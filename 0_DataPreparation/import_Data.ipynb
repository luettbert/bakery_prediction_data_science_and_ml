{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titel: Import data\n",
    "## Author: Achraf Aboukinana\n",
    "\n",
    "## Beschreibung des Codes\n",
    "\n",
    "Dieser Code dient der Analyse, Bereinigung und Kombination von Datensätzen, um eine zentrale und bereinigte Datenbasis zu erstellen. Die Hauptaufgaben sind wie folgt:\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Datenimport**\n",
    "- Die drei Datensätze `kiwo.csv`, `umsatzdaten_gekuerzt.csv` und `wetterdaten.csv` werden eingelesen.\n",
    "- Die Spalte `Datum` wird als Datumsformat (`datetime`) geparst.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Datenexploration**\n",
    "Eine Funktion `explore_data` analysiert jeden DataFrame:\n",
    "- Form des DataFrames (Zeilen und Spalten).\n",
    "- Vorschau der ersten fünf Zeilen.\n",
    "- Spaltennamen, Datentypen und fehlende Werte pro Spalte.\n",
    "- Beschreibende Statistiken.\n",
    "- Anzahl der Duplikate.\n",
    "- Zeitraum der Daten (falls `Datum`-Spalte vorhanden).\n",
    "\n",
    "Diese Funktion wird auf alle Datensätze angewendet.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Zusammenführung der Datensätze**\n",
    "- **Erster Merge**: `umsatzdaten_gekuerzt_data` und `wetter_data` werden anhand der Spalte `Datum` zusammengeführt.\n",
    "- **Zweiter Merge**: Die zusammengeführten Daten werden mit `kiwo_data` kombiniert, wodurch eine neue Spalte `KielerWoche` entsteht:\n",
    "  - Fehlende Werte in `KielerWoche` (für nicht-Kieler-Woche-Tage) werden mit `0` gefüllt.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Analyse fehlender Werte**\n",
    "- Anzahl der fehlenden Werte (`NaN`) pro Spalte wird berechnet.\n",
    "- Zeilen mit fehlenden Werten werden entfernt.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Speichern der Ergebnisse**\n",
    "- Der kombinierte Datensatz wird in zwei Versionen gespeichert:\n",
    "  - **Mit NaN-Werten**: `final_data_withNaN.csv`.\n",
    "  - **Ohne NaN-Werte**: `final_data.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Vergleich der Zeilenanzahl**\n",
    "- Die Anzahl der Zeilen vor und nach der Bereinigung wird verglichen, um den Verlust durch das Entfernen von `NaN`-Werten zu zeigen.\n",
    "\n",
    "---\n",
    "\n",
    "## **Zweck des Codes**\n",
    "1. **Datenbereinigung**: Sicherstellung von konsistenten und vollständigen Daten.\n",
    "2. **Kombination der Datensätze**: Erstellung einer zentralen, einheitlichen Datenbasis.\n",
    "3. **Markierung besonderer Tage**: Identifikation der Kieler Woche-Tage (`KielerWoche`).\n",
    "4. **Analyse-Ready**: Der bereinigte Datensatz dient als Grundlage für Analysen oder Modelle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import holidays\n",
    "# Import Data\n",
    "kiwo_data = pd.read_csv('kiwo.csv', parse_dates=['Datum'])\n",
    "umsatzdaten_gekuerzt_data = pd.read_csv('umsatzdaten_gekuerzt.csv', parse_dates=['Datum'])\n",
    "wetter_data = pd.read_csv('wetterdaten.csv', parse_dates=['Datum'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Funktion zur Datenexploration\n",
    "def explore_data(df, name):\n",
    "    print(f\"\\n{'='*50}\\nExploration für {name}\\n{'='*50}\")\n",
    "    \n",
    "    # Überblick\n",
    "    print(f\"Form: {df.shape[0]} Zeilen, {df.shape[1]} Spalten\")\n",
    "    print(\"Erste 5 Zeilen:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Spaltennamen und Typen\n",
    "    print(\"\\nSpalten und Datentypen:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    # Fehlende Werte\n",
    "    print(\"\\nFehlende Werte pro Spalte:\")\n",
    "    print(df.isna().sum())\n",
    "    \n",
    "    # Beschreibende Statistik\n",
    "    print(\"\\nBeschreibende Statistik:\")\n",
    "    print(df.describe(include='all'))\n",
    "    \n",
    "    # Duplikate\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    print(f\"\\nAnzahl der Duplikate: {duplicate_count}\")\n",
    "\n",
    "    # Wichtige Spalten\n",
    "    if 'Datum' in df.columns:\n",
    "        print(\"\\nZeitraum der Daten:\")\n",
    "        print(f\"Min Datum: {df['Datum'].min()}, Max Datum: {df['Datum'].max()}\")\n",
    "    else:\n",
    "        print(\"\\nKeine 'Datum'-Spalte in diesem DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Exploration der einzelnen Dateien\n",
    "explore_data(kiwo_data, \"DATA/Kiwo Data\")\n",
    "explore_data(umsatzdaten_gekuerzt_data, \"DATA/Umsatzdaten Gekürzt\")\n",
    "explore_data(wetter_data, \"DATA/Wetter Data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Datei einlesen mit manuellem Trennzeichen\n",
    "file_path = \"DATA/inflation.csv\"  # Pfad zur Datei\n",
    "data = pd.read_csv(file_path, delimiter=',')\n",
    "\n",
    "\n",
    "\n",
    "# Kategorisierung der Veränderung im Vorjahresmonat\n",
    "def categorize_inflation(row):\n",
    "    if row[\"Veränderung_Vormonat\"] > 0:\n",
    "        return \"Positiv\"\n",
    "    elif row[\"Veränderung_Vormonat\"] < 0:\n",
    "        return \"Negativ\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# Neue Spalte für Inflation-Kategorisierung hinzufügen\n",
    "data[\"Inflation_Kategorisierung_vormonat\"] = data.apply(categorize_inflation, axis=1)\n",
    "\n",
    "# Dummy-Encoding der Kategorisierungen\n",
    "data = pd.get_dummies(data, columns=[\"Inflation_Kategorisierung_vormonat\"], drop_first=True)\n",
    "\n",
    "### nach paar änderungen habe ich den tabelle vorbereiten so dass wir es erstmal mergen und in unsere model benutzen \n",
    "# In eine neue CSV-Datei speichern\n",
    "data.to_csv(\"DATA/inflation.csv\", index=False)\n",
    "\n",
    "# Daten anzeigen\n",
    "print(data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import holidays\n",
    "\n",
    "# Merge Umsatzdaten mit Wetterdaten auf 'Datum'\n",
    "merged_data = pd.merge(umsatzdaten_gekuerzt_data, wetter_data, on='Datum', how='inner')\n",
    "\n",
    "# Füge KielerWoche-Information hinzu und ersetze fehlende Werte durch 0\n",
    "final_data = pd.merge(merged_data, kiwo_data[['Datum', 'KielerWoche']], on='Datum', how='left')\n",
    "final_data['KielerWoche'] = final_data['KielerWoche'].fillna(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Anzahl der NaN-Werte überprüfen\n",
    "nan_counts = final_data.isna().sum()\n",
    "print(\"Anzahl der NaN-Werte pro Spalte:\")\n",
    "print(nan_counts)\n",
    "\n",
    "# Entferne Zeilen mit NaN-Werten\n",
    "clean_data = final_data.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# **Zeitabhängige Variablen hinzufügen**\n",
    "clean_data['Wochentag'] = clean_data['Datum'].dt.dayofweek  # Montag=0, Sonntag=6\n",
    "clean_data['Monat'] = clean_data['Datum'].dt.month\n",
    "clean_data['Jahreszeit'] = clean_data['Datum'].dt.month % 12 // 3 + 1  # Frühling=1, Sommer=2, Herbst=3, Winter=4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7009 entries, 0 to 7008\n",
      "Data columns (total 27 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Datum                 7009 non-null   object \n",
      " 1   Warengruppe           7009 non-null   int64  \n",
      " 2   Umsatz                7009 non-null   float64\n",
      " 3   Bewoelkung            7009 non-null   float64\n",
      " 4   Temperatur            7009 non-null   float64\n",
      " 5   Wettercode            7009 non-null   float64\n",
      " 6   KielerWoche           7009 non-null   int64  \n",
      " 7   Wochentag             7009 non-null   int64  \n",
      " 8   Monat                 7009 non-null   int64  \n",
      " 9   Jahreszeit_1          7009 non-null   bool   \n",
      " 10  Jahreszeit_2          7009 non-null   bool   \n",
      " 11  Jahreszeit_3          7009 non-null   bool   \n",
      " 12  Jahreszeit_4          7009 non-null   bool   \n",
      " 13  Wetter_Kalt           7009 non-null   bool   \n",
      " 14  Wetter_Mild           7009 non-null   bool   \n",
      " 15  Wetter_Warm           7009 non-null   bool   \n",
      " 16  Feiertag              7009 non-null   int64  \n",
      " 17  KielLauf              7009 non-null   int64  \n",
      " 18  Kieler_Triathlon      7009 non-null   int64  \n",
      " 19  Fußball               7009 non-null   int64  \n",
      " 20  PaycheckEffect        7009 non-null   int64  \n",
      " 21  InflationSensitivity  7009 non-null   object \n",
      " 22  Sensitivity_High      7009 non-null   bool   \n",
      " 23  Sensitivity_Moderate  7009 non-null   bool   \n",
      " 24  Wind_Nicht windig     7009 non-null   bool   \n",
      " 25  Wind_Windig           7009 non-null   bool   \n",
      " 26  Wind_Zu windig        7009 non-null   bool   \n",
      "dtypes: bool(12), float64(4), int64(9), object(2)\n",
      "memory usage: 903.6+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "clean_data= pd.read_csv('DATA/final_data.csv')\n",
    "clean_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7009 entries, 0 to 7008\n",
      "Data columns (total 44 columns):\n",
      " #   Column                                      Non-Null Count  Dtype  \n",
      "---  ------                                      --------------  -----  \n",
      " 0   Datum                                       7009 non-null   object \n",
      " 1   Warengruppe                                 7009 non-null   int64  \n",
      " 2   Umsatz                                      7009 non-null   float64\n",
      " 3   Bewoelkung                                  7009 non-null   float64\n",
      " 4   Temperatur                                  7009 non-null   float64\n",
      " 5   Wettercode                                  7009 non-null   float64\n",
      " 6   KielerWoche                                 7009 non-null   int64  \n",
      " 7   Wochentag                                   7009 non-null   int64  \n",
      " 8   Monat                                       7009 non-null   int64  \n",
      " 9   Jahreszeit_1                                7009 non-null   bool   \n",
      " 10  Jahreszeit_2                                7009 non-null   bool   \n",
      " 11  Jahreszeit_3                                7009 non-null   bool   \n",
      " 12  Jahreszeit_4                                7009 non-null   bool   \n",
      " 13  Wetter_Kalt                                 7009 non-null   bool   \n",
      " 14  Wetter_Mild                                 7009 non-null   bool   \n",
      " 15  Wetter_Warm                                 7009 non-null   bool   \n",
      " 16  Feiertag                                    7009 non-null   int64  \n",
      " 17  KielLauf                                    7009 non-null   int64  \n",
      " 18  Kieler_Triathlon                            7009 non-null   int64  \n",
      " 19  Fußball                                     7009 non-null   int64  \n",
      " 20  PaycheckEffect                              7009 non-null   int64  \n",
      " 21  InflationSensitivity                        7009 non-null   object \n",
      " 22  Sensitivity_High                            7009 non-null   bool   \n",
      " 23  Sensitivity_Moderate                        7009 non-null   bool   \n",
      " 24  Wind_Nicht windig                           7009 non-null   bool   \n",
      " 25  Wind_Windig                                 7009 non-null   bool   \n",
      " 26  Wind_Zu windig                              7009 non-null   bool   \n",
      " 27  Jahr                                        7009 non-null   int64  \n",
      " 28  Verbraucherpreisindex                       7009 non-null   float64\n",
      " 29  Veränderung_Vorjahresmonat                  7009 non-null   float64\n",
      " 30  Veränderung_Vormonat                        7009 non-null   float64\n",
      " 31  Inflation_Kategorisierung                   7009 non-null   object \n",
      " 32  Inflation_Kategorisierung_Neutral           7009 non-null   bool   \n",
      " 33  Inflation_Kategorisierung_Positiv           7009 non-null   bool   \n",
      " 34  Inflation_Kategorisierung_vormonat_Neutral  7009 non-null   bool   \n",
      " 35  Inflation_Kategorisierung_vormonat_Positiv  7009 non-null   bool   \n",
      " 36  Jahreszeit                                  7009 non-null   object \n",
      " 37  Gefühl                                      7009 non-null   object \n",
      " 38  gefühl_Kalt                                 7009 non-null   bool   \n",
      " 39  gefühl_Mild                                 7009 non-null   bool   \n",
      " 40  gefühl_Warm                                 7009 non-null   bool   \n",
      " 41  Ferien                                      7009 non-null   int64  \n",
      " 42  Tag_Kategorie                               7009 non-null   object \n",
      " 43  Wochenende                                  7009 non-null   int64  \n",
      "dtypes: bool(19), float64(7), int64(12), object(6)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_data= pd.read_csv('DATA/final_data_x.csv')\n",
    "clean_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7009 entries, 0 to 7008\n",
      "Data columns (total 42 columns):\n",
      " #   Column                                       Non-Null Count  Dtype  \n",
      "---  ------                                       --------------  -----  \n",
      " 0   Datum                                        7009 non-null   object \n",
      " 1   Umsatz                                       7009 non-null   float64\n",
      " 2   Wettercode                                   7009 non-null   float64\n",
      " 3   KielerWoche                                  7009 non-null   int64  \n",
      " 4   Jahreszeit_1                                 7009 non-null   int64  \n",
      " 5   Jahreszeit_2                                 7009 non-null   int64  \n",
      " 6   Jahreszeit_3                                 7009 non-null   int64  \n",
      " 7   Jahreszeit_4                                 7009 non-null   int64  \n",
      " 8   Wetter_Kalt                                  7009 non-null   int64  \n",
      " 9   Wetter_Mild                                  7009 non-null   int64  \n",
      " 10  Wetter_Warm                                  7009 non-null   int64  \n",
      " 11  Feiertag                                     7009 non-null   int64  \n",
      " 12  KielLauf                                     7009 non-null   int64  \n",
      " 13  Kieler_Triathlon                             7009 non-null   int64  \n",
      " 14  Fußball                                      7009 non-null   int64  \n",
      " 15  PaycheckEffect                               7009 non-null   int64  \n",
      " 16  Sensitivity_High                             7009 non-null   int64  \n",
      " 17  Sensitivity_Moderate                         7009 non-null   int64  \n",
      " 18  Wind_Nicht windig                            7009 non-null   int64  \n",
      " 19  Wind_Windig                                  7009 non-null   int64  \n",
      " 20  Wind_Zu windig                               7009 non-null   int64  \n",
      " 21  Inflation_Kategorisierung_Neutral            7009 non-null   int64  \n",
      " 22  Inflation_Kategorisierung_Positiv            7009 non-null   int64  \n",
      " 23  Inflation_Kategorisierung_vormonat_Neutral   7009 non-null   int64  \n",
      " 24  Inflation_Kategorisierung_vormonat_Positiv   7009 non-null   int64  \n",
      " 25  gefühl_Kalt                                  7009 non-null   int64  \n",
      " 26  gefühl_Mild                                  7009 non-null   int64  \n",
      " 27  gefühl_Warm                                  7009 non-null   int64  \n",
      " 28  Wochentag_0                                  7009 non-null   int64  \n",
      " 29  Wochentag_1                                  7009 non-null   int64  \n",
      " 30  Wochentag_2                                  7009 non-null   int64  \n",
      " 31  Wochentag_3                                  7009 non-null   int64  \n",
      " 32  Wochentag_4                                  7009 non-null   int64  \n",
      " 33  Wochentag_5                                  7009 non-null   int64  \n",
      " 34  Wochentag_6                                  7009 non-null   int64  \n",
      " 35  Brot                                         7009 non-null   int64  \n",
      " 36  Brötchen                                     7009 non-null   int64  \n",
      " 37  Croissant                                    7009 non-null   int64  \n",
      " 38  Konditorei                                   7009 non-null   int64  \n",
      " 39  Kuchen                                       7009 non-null   int64  \n",
      " 40  Saisonbrot                                   7009 non-null   int64  \n",
      " 41  Ferien                                       7009 non-null   int64  \n",
      "dtypes: float64(2), int64(39), object(1)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_data= pd.read_csv('../2_BaselineModel/model_data.csv')\n",
    "clean_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7009 entries, 0 to 7008\n",
      "Data columns (total 36 columns):\n",
      " #   Column                                      Non-Null Count  Dtype  \n",
      "---  ------                                      --------------  -----  \n",
      " 0   Datum                                       7009 non-null   object \n",
      " 1   Warengruppe                                 7009 non-null   int64  \n",
      " 2   Umsatz                                      7009 non-null   float64\n",
      " 3   Bewoelkung                                  7009 non-null   float64\n",
      " 4   Temperatur                                  7009 non-null   float64\n",
      " 5   Wettercode                                  7009 non-null   float64\n",
      " 6   KielerWoche                                 7009 non-null   int64  \n",
      " 7   Wochentag                                   7009 non-null   int64  \n",
      " 8   Monat                                       7009 non-null   int64  \n",
      " 9   Jahreszeit_1                                7009 non-null   bool   \n",
      " 10  Jahreszeit_2                                7009 non-null   bool   \n",
      " 11  Jahreszeit_3                                7009 non-null   bool   \n",
      " 12  Jahreszeit_4                                7009 non-null   bool   \n",
      " 13  Wetter_Kalt                                 7009 non-null   bool   \n",
      " 14  Wetter_Mild                                 7009 non-null   bool   \n",
      " 15  Wetter_Warm                                 7009 non-null   bool   \n",
      " 16  Feiertag                                    7009 non-null   int64  \n",
      " 17  KielLauf                                    7009 non-null   int64  \n",
      " 18  Kieler_Triathlon                            7009 non-null   int64  \n",
      " 19  Fußball                                     7009 non-null   int64  \n",
      " 20  PaycheckEffect                              7009 non-null   int64  \n",
      " 21  InflationSensitivity                        7009 non-null   object \n",
      " 22  Sensitivity_High                            7009 non-null   bool   \n",
      " 23  Sensitivity_Moderate                        7009 non-null   bool   \n",
      " 24  Wind_Nicht windig                           7009 non-null   bool   \n",
      " 25  Wind_Windig                                 7009 non-null   bool   \n",
      " 26  Wind_Zu windig                              7009 non-null   bool   \n",
      " 27  Jahr                                        7009 non-null   int64  \n",
      " 28  Verbraucherpreisindex                       7009 non-null   float64\n",
      " 29  Veränderung_Vorjahresmonat                  7009 non-null   float64\n",
      " 30  Veränderung_Vormonat                        7009 non-null   float64\n",
      " 31  Inflation_Kategorisierung                   7009 non-null   object \n",
      " 32  Inflation_Kategorisierung_Neutral           7009 non-null   bool   \n",
      " 33  Inflation_Kategorisierung_Positiv           7009 non-null   bool   \n",
      " 34  Inflation_Kategorisierung_vormonat_Neutral  7009 non-null   bool   \n",
      " 35  Inflation_Kategorisierung_vormonat_Positiv  7009 non-null   bool   \n",
      "dtypes: bool(16), float64(7), int64(10), object(3)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_data= pd.read_csv('DATA/final_data_c.csv')\n",
    "clean_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Jahreszeit bestimmen\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return \"Winter\"\n",
    "    elif month in [3, 4, 5]:\n",
    "        return \"Frühling\"\n",
    "    elif month in [6, 7, 8]:\n",
    "        return \"Sommer\"\n",
    "    elif month in [9, 10, 11]:\n",
    "        return \"Herbst\"\n",
    "\n",
    "clean_data['Jahreszeit'] = clean_data['Monat'].apply(get_season)\n",
    "\n",
    "# Gefühl abhängig von Temperatur und Jahreszeit\n",
    "def temperature_feeling(temp, season):\n",
    "    if season == \"Winter\":\n",
    "        if temp <= 0:\n",
    "            return \"Kalt\"\n",
    "        elif temp <= 10:\n",
    "            return \"Mild\"\n",
    "        else:\n",
    "            return \"Warm\"\n",
    "    elif season == \"Frühling\":\n",
    "        if temp <= 10:\n",
    "            return \"Kalt\"\n",
    "        elif temp <= 20:\n",
    "            return \"Mild\"\n",
    "        else:\n",
    "            return \"Warm\"\n",
    "    elif season == \"Sommer\":\n",
    "        if temp <= 15:\n",
    "            return \"Kalt\"\n",
    "        elif temp <= 25:\n",
    "            return \"Mild\"\n",
    "        else:\n",
    "            return \"Warm\"\n",
    "    elif season == \"Herbst\":\n",
    "        if temp <= 10:\n",
    "            return \"Kalt\"\n",
    "        elif temp <= 20:\n",
    "            return \"Mild\"\n",
    "        else:\n",
    "            return \"Warm\"\n",
    "\n",
    "clean_data['Gefühl'] = clean_data.apply(lambda x: temperature_feeling(x['Temperatur'], x['Jahreszeit']), axis=1)\n",
    "\n",
    "# Dummy-Encoding\n",
    "gefühl_dummies = pd.get_dummies(clean_data['Gefühl'],prefix='gefühl')\n",
    "\n",
    "# Dummy-Variablen anhängen und Originalspalten löschen\n",
    "clean_data = pd.concat([clean_data,gefühl_dummies], axis=1)\n",
    "#gefühl_dummies.drop(columns=['Gefühl'], inplace=True)\n",
    "\n",
    "clean_data.to_csv('final_data_x.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# **Dummy-Encoding für Jahreszeit und Wetterkategorie**\n",
    "jahreszeit_dummies = pd.get_dummies(clean_data['Jahreszeit'], prefix=\"Jahreszeit\")\n",
    "wetter_dummies = pd.get_dummies(clean_data['Wetterkategorie'], prefix=\"Wetter\")\n",
    "\n",
    "# Dummy-Variablen anhängen und Originalspalten löschen\n",
    "clean_data = pd.concat([clean_data, jahreszeit_dummies, wetter_dummies], axis=1)\n",
    "clean_data.drop(columns=['Jahreszeit', 'Wetterkategorie'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# **Feiertage hinzufügen**\n",
    "def get_feiertage(year):\n",
    "    de_holidays = holidays.Germany(years=year)\n",
    "    return list(de_holidays.keys())\n",
    "\n",
    "# Feiertagsinformationen für alle Jahre im Datensatz\n",
    "#feiertage_set = {holiday for year in clean_data['Datum'].dt.year.unique() for holiday in get_feiertage(year)}\n",
    "\n",
    "# Feiertagsspalte erstellen\n",
    "#clean_data['Feiertag'] = clean_data['Datum'].apply(lambda x: 1 if x.date() in feiertage_set else 0)\n",
    "\n",
    "# **Besondere Events (KielLauf, Kieler Triathlon) hinzufügen**\n",
    "kieler_triathlon_daten = pd.to_datetime(['2013-08-04', '2014-08-03', '2015-08-02', '2016-08-07', '2017-08-06', \n",
    "                                         '2018-08-05', '2019-08-04'])\n",
    "kiellauf_daten = pd.to_datetime([\"2013-09-08\", \"2014-09-14\", \"2015-09-13\", \"2016-09-11\", \n",
    "                                 \"2017-09-10\", \"2018-09-09\", \"2019-09-08\"])\n",
    "important_games_germany = pd.to_datetime([\n",
    "    # FIFA World Cup 2014\n",
    "    \"2014-07-08\",  # Germany 7–1 Brazil (Semifinal)\n",
    "    \"2014-07-13\",  # Germany 1–0 Argentina (Final)\n",
    "\n",
    "    # UEFA Euro 2016\n",
    "    \"2016-07-02\",  # Germany 1–1 Italy (6–5 on penalties, Quarterfinal)\n",
    "    \"2016-07-07\",  # Germany 0–2 France (Semifinal)\n",
    "\n",
    "    # FIFA Confederations Cup 2017\n",
    "    \"2017-06-19\",  # Germany 3–2 Australia\n",
    "    \"2017-06-22\",  # Germany 1–1 Chile\n",
    "    \"2017-06-25\",  # Germany 3–1 Cameroon\n",
    "    \"2017-06-29\",  # Germany 4–1 Mexico (Semifinal)\n",
    "    \"2017-07-02\",  # Germany 1–0 Chile (Final)\n",
    "\n",
    "    # FIFA World Cup 2018\n",
    "    \"2018-06-17\",  # Germany 0–1 Mexico (Group stage)\n",
    "    \"2018-06-27\",  # Germany 0–2 South Korea (Group stage, eliminated)\n",
    "\n",
    "    # Olympic Games 2016 (Men's Football)\n",
    "    \"2016-08-20\"   # Germany 1–1 Brazil (4–5 on penalties, Final)\n",
    "])\n",
    "\n",
    "clean_data['KielLauf'] = clean_data['Datum'].apply(lambda x: 1 if x.date() in kiellauf_daten.date else 0)\n",
    "clean_data['Kieler_Triathlon'] = clean_data['Datum'].apply(lambda x: 1 if x.date() in kieler_triathlon_daten.date else 0)\n",
    "clean_data['Fußball'] = clean_data['Datum'].apply(lambda x: 1 if x.date() in important_games_germany.date else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# **PaycheckEffect (Gehaltszahlungen)**\n",
    "clean_data['PaycheckEffect'] = clean_data['Datum'].apply(\n",
    "    lambda x: 1 if x.day >= 27 or x.day <= 5 else 0\n",
    ")\n",
    "\n",
    "# Inflation sensitivity mapping based on WarenGruppe\n",
    "sensitivity_mapping = {\n",
    "    1: \"High\",   # Brot\n",
    "    2: \"High\",   # Brötchen\n",
    "    3: \"Moderate\",  # Croissant\n",
    "    4: \"Moderate\",  # Konditorei\n",
    "    5: \"Moderate\",  # Kuchen\n",
    "    6: \"High\"    # Saisonbrot\n",
    "}\n",
    "\n",
    "# Map the sensitivity to the WarenGruppe\n",
    "clean_data[\"InflationSensitivity\"] = clean_data[\"Warengruppe\"].map(sensitivity_mapping)\n",
    "\n",
    "# Perform dummy encoding for sensitivity levels, excluding 'Low'\n",
    "dummy_encoded = pd.get_dummies(clean_data[\"InflationSensitivity\"], prefix=\"Sensitivity\").drop(columns=[\"Sensitivity_Low\"], errors=\"ignore\")\n",
    "\n",
    "# Concatenate the dummy columns with the original DataFrame\n",
    "clean_data = pd.concat([clean_data, dummy_encoded], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# **Windkategorie basierend auf Windgeschwindigkeit**\n",
    "def wind_kategorie(wind):\n",
    "    if wind < 10:\n",
    "        return \"Nicht windig\"\n",
    "    elif wind <= 20:\n",
    "        return \"Windig\"\n",
    "    else:\n",
    "        return \"Sehr windig\" #TODO zu => sehr\n",
    "\n",
    "clean_data['Windkategorie'] = clean_data['Windgeschwindigkeit'].apply(wind_kategorie)\n",
    "\n",
    "# Dummy-Variablen für Windkategorien erstellen\n",
    "wind_dummies = pd.get_dummies(clean_data['Windkategorie'], prefix=\"Wind\")\n",
    "clean_data = pd.concat([clean_data, wind_dummies], axis=1)\n",
    "\n",
    "# Originalspalten löschen\n",
    "clean_data.drop(columns=['Windkategorie', 'Windgeschwindigkeit'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# **Speichern der Ergebnisse**\n",
    "final_data.to_csv('final_data_withNaN.csv', index=False)  # Mit NaN-Werten\n",
    "clean_data.to_csv('final_data.csv', index=False)         # Ohne NaN-Werte\n",
    "\n",
    "# Zeilenanzahl vor und nach dem Entfernen von NaN\n",
    "difference = len(final_data) - len(clean_data)\n",
    "print(f\"Zeilen mit NaN entfernt: {difference}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# **Zusammenfassung**\n",
    "clean_data.head()\n",
    "clean_data.info()\n",
    "clean_data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year from the date in Table 2\n",
    "clean_data['Jahr'] = pd.to_datetime(clean_data['Datum']).dt.year\n",
    "clean_data = pd.merge(clean_data,data,on = ['Jahr', 'Monat'] )\n",
    "clean_data.to_csv('final_data_c.csv', index=False)         # Ohne NaN-Werte\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "ferien_kiel = [\n",
    "    # Schulferien 2013\n",
    "    ('2013-01-01', '2013-01-05'),  # Weihnachtsferien\n",
    "    ('2013-03-25', '2013-04-06'),  # Osterferien\n",
    "    ('2013-06-24', '2013-08-03'),  # Sommerferien\n",
    "    ('2013-10-04', '2013-10-19'),  # Herbstferien\n",
    "    ('2013-12-23', '2014-01-04'),  # Weihnachtsferien\n",
    "\n",
    "    # Schulferien 2014\n",
    "    ('2014-04-07', '2014-04-22'),  # Osterferien\n",
    "    ('2014-07-14', '2014-08-23'),  # Sommerferien\n",
    "    ('2014-10-20', '2014-11-01'),  # Herbstferien\n",
    "    ('2014-12-22', '2015-01-06'),  # Weihnachtsferien\n",
    "\n",
    "    # Schulferien 2015\n",
    "    ('2015-04-01', '2015-04-18'),  # Osterferien\n",
    "    ('2015-07-16', '2015-08-29'),  # Sommerferien\n",
    "    ('2015-10-19', '2015-10-31'),  # Herbstferien\n",
    "    ('2015-12-23', '2016-01-06'),  # Weihnachtsferien\n",
    "\n",
    "    # Schulferien 2016\n",
    "    ('2016-03-24', '2016-04-09'),  # Osterferien\n",
    "    ('2016-07-25', '2016-09-03'),  # Sommerferien\n",
    "    ('2016-10-17', '2016-10-29'),  # Herbstferien\n",
    "    ('2016-12-23', '2017-01-07'),  # Weihnachtsferien\n",
    "\n",
    "    # Schulferien 2017\n",
    "    ('2017-04-07', '2017-04-22'),  # Osterferien\n",
    "    ('2017-07-24', '2017-09-02'),  # Sommerferien\n",
    "    ('2017-10-16', '2017-10-28'),  # Herbstferien\n",
    "    ('2017-12-21', '2018-01-06'),  # Weihnachtsferien\n",
    "\n",
    "    # Schulferien 2018\n",
    "    ('2018-03-29', '2018-04-13'),  # Osterferien\n",
    "    ('2018-07-09', '2018-08-18'),  # Sommerferien\n",
    "    ('2018-10-01', '2018-10-13'),  # Herbstferien\n",
    "    ('2018-12-21', '2019-01-04'),  # Weihnachtsferien\n",
    "\n",
    "    # Schulferien 2019\n",
    "    ('2019-04-04', '2019-04-18'),  # Osterferien\n",
    "    ('2019-07-01', '2019-08-10'),  # Sommerferien\n",
    "    ('2019-10-04', '2019-10-19'),  # Herbstferien\n",
    "    ('2019-12-23', '2020-01-06'),  # Weihnachtsferien\n",
    "\n",
    "    # Schulferien 2020\n",
    "    ('2020-03-30', '2020-04-17'),  # Osterferien\n",
    "    ('2020-06-29', '2020-08-08'),  # Sommerferien\n",
    "    ('2020-10-05', '2020-10-17'),  # Herbstferien\n",
    "    ('2020-12-23', '2021-01-06'),  # Weihnachtsferien\n",
    "]\n",
    "\n",
    "# Konvertiere Ferien zu einer Liste von Datumsobjekten\n",
    "ferien_tage = []\n",
    "for start, end in ferien_kiel:\n",
    "    start_date = datetime.strptime(start, '%Y-%m-%d')\n",
    "    end_date = datetime.strptime(end, '%Y-%m-%d')\n",
    "    while start_date <= end_date:\n",
    "        ferien_tage.append(start_date)\n",
    "        start_date += timedelta(days=1)\n",
    "\n",
    "\n",
    "\n",
    "# CSV-Datei laden\n",
    "data = pd.read_csv('../2_BaselineModel/model_data.csv')\n",
    "\n",
    "# Datumsspalte in datetime konvertieren\n",
    "data['Datum'] = pd.to_datetime(data['Datum'])\n",
    "\n",
    "# Set der Ferientage für schnellen Zugriff\n",
    "ferien_set = set(ferien_tage)\n",
    "\n",
    "# Spalte hinzufügen: 1 für Ferien, 0 für keine Ferien\n",
    "data['Ferien'] = data['Datum'].apply(lambda x: 1 if x in ferien_set else 0)\n",
    "\n",
    "data.to_csv('../2_BaselineModel/model_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../2_BaselineModel/model_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# Spalte umbenennen\n",
    "df.rename(columns={\"Warengruppe_1\": \"Brot\"}, inplace=True)\n",
    "df.rename(columns={\"Warengruppe_2\": \"Brötchen\"}, inplace=True)\n",
    "df.rename(columns={\"Warengruppe_3\": \"Croissant\"}, inplace=True)\n",
    "df.rename(columns={\"Warengruppe_4\": \"Konditorei\"}, inplace=True)\n",
    "df.rename(columns={\"Warengruppe_5\": \"Kuchen\"}, inplace=True)\n",
    "df.rename(columns={\"Warengruppe_6\": \"Saisonbrot\"}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Änderungen speichern\n",
    "df.to_csv(file_path, index=False)  # Überschreibt die Originaldatei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../2_BaselineModel/model_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# Spalte umbenennen\n",
    "df.rename(columns={\"Wochentag_0\": \"Montag\"}, inplace=True)\n",
    "df.rename(columns={\"Wochentag_1\": \"Dienstag\"}, inplace=True)\n",
    "df.rename(columns={\"Wochentag_2\": \"Mittwoch\"}, inplace=True)\n",
    "df.rename(columns={\"Wochentag_3\": \"Donnerstag\"}, inplace=True)\n",
    "df.rename(columns={\"Wochentag_4\": \"Freitag\"}, inplace=True)\n",
    "df.rename(columns={\"Wochentag_5\": \"Samstag\"}, inplace=True)\n",
    "df.rename(columns={\"Wochentag_6\": \"Sonntag\"}, inplace=True)\n",
    "\n",
    "\n",
    "# Änderungen speichern\n",
    "df.to_csv(file_path, index=False)  # Überschreibt die Originaldatei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Datum', 'Umsatz', 'Wettercode', 'KielerWoche', 'Jahreszeit_1',\n",
      "       'Jahreszeit_2', 'Jahreszeit_3', 'Jahreszeit_4', 'Wetter_Kalt',\n",
      "       'Wetter_Mild', 'Wetter_Warm', 'Feiertag', 'KielLauf',\n",
      "       'Kieler_Triathlon', 'Fußball', 'PaycheckEffect', 'Sensitivity_High',\n",
      "       'Sensitivity_Moderate', 'Wind_Nicht windig', 'Wind_Windig',\n",
      "       'Wind_Zu windig', 'Inflation_Kategorisierung_Neutral',\n",
      "       'Inflation_Kategorisierung_Positiv',\n",
      "       'Inflation_Kategorisierung_vormonat_Neutral',\n",
      "       'Inflation_Kategorisierung_vormonat_Positiv', 'gefühl_Kalt',\n",
      "       'gefühl_Mild', 'gefühl_Warm', 'Wochentag_0', 'Wochentag_1',\n",
      "       'Wochentag_2', 'Wochentag_3', 'Wochentag_4', 'Wochentag_5',\n",
      "       'Wochentag_6', 'Brot', 'Brötchen', 'Croissant', 'Konditorei', 'Kuchen',\n",
      "       'Saisonbrot', 'Ferien'],\n",
      "      dtype='object')\n",
      "Index(['Datum', 'Umsatz', 'Wettercode', 'KielerWoche', 'Jahreszeit_1',\n",
      "       'Jahreszeit_2', 'Jahreszeit_3', 'Jahreszeit_4', 'Wetter_Kalt',\n",
      "       'Wetter_Mild', 'Wetter_Warm', 'Feiertag', 'KielLauf',\n",
      "       'Kieler_Triathlon', 'Fußball', 'PaycheckEffect', 'Sensitivity_High',\n",
      "       'Sensitivity_Moderate', 'Wind_Nicht windig', 'Wind_Windig',\n",
      "       'Wind_Zu windig', 'Inflation_Kategorisierung_Neutral',\n",
      "       'Inflation_Kategorisierung_Positiv',\n",
      "       'Inflation_Kategorisierung_vormonat_Neutral',\n",
      "       'Inflation_Kategorisierung_vormonat_Positiv', 'gefühl_Kalt',\n",
      "       'gefühl_Mild', 'gefühl_Warm', 'Wochentag_0', 'Wochentag_1',\n",
      "       'Wochentag_2', 'Wochentag_3', 'Wochentag_4', 'Wochentag_5',\n",
      "       'Wochentag_6', 'Brot', 'Brötchen', 'Croissant', 'Konditorei', 'Kuchen',\n",
      "       'Saisonbrot', 'Ferien', 'Wochenende'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "file_path = \"DATA/final_data_x.csv\"\n",
    "df.columns = df.columns.str.strip()\n",
    "#file_path = \"../2_BaselineModel/model_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Neue Spalte basierend auf Wochentagen erstellen\n",
    "df['Tag_Kategorie'] = df['Wochentag'].apply(lambda x: 'Montag_bis_Freitag' if x < 5 else 'Wochenende')\n",
    "# Neue Spalte für Wochenenden erstellen\n",
    "df['Wochenende'] = df['Wochentag'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "df.to_csv(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = \"../2_BaselineModel/model_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "# Neue Spalte \"Wochenende\" hinzufügen: 1 für Samstag oder Sonntag, sonst 0\n",
    "df['Wochenende'] = df[['Samstag', 'Sonntag']].sum(axis=1)\n",
    "\n",
    "\n",
    "df.to_csv(file_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
