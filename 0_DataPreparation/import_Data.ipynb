{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titel: Import data\n",
    "## Author: Achraf Aboukinana\n",
    "\n",
    "## Beschreibung des Codes\n",
    "\n",
    "Dieser Code dient der Analyse, Bereinigung und Kombination von Datensätzen, um eine zentrale und bereinigte Datenbasis zu erstellen. Die Hauptaufgaben sind wie folgt:\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Datenimport**\n",
    "- Die drei Datensätze `kiwo.csv`, `umsatzdaten_gekuerzt.csv` und `wetterdaten.csv` werden eingelesen.\n",
    "- Die Spalte `Datum` wird als Datumsformat (`datetime`) geparst.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Datenexploration**\n",
    "Eine Funktion `explore_data` analysiert jeden DataFrame:\n",
    "- Form des DataFrames (Zeilen und Spalten).\n",
    "- Vorschau der ersten fünf Zeilen.\n",
    "- Spaltennamen, Datentypen und fehlende Werte pro Spalte.\n",
    "- Beschreibende Statistiken.\n",
    "- Anzahl der Duplikate.\n",
    "- Zeitraum der Daten (falls `Datum`-Spalte vorhanden).\n",
    "\n",
    "Diese Funktion wird auf alle Datensätze angewendet.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Zusammenführung der Datensätze**\n",
    "- **Erster Merge**: `umsatzdaten_gekuerzt_data` und `wetter_data` werden anhand der Spalte `Datum` zusammengeführt.\n",
    "- **Zweiter Merge**: Die zusammengeführten Daten werden mit `kiwo_data` kombiniert, wodurch eine neue Spalte `KielerWoche` entsteht:\n",
    "  - Fehlende Werte in `KielerWoche` (für nicht-Kieler-Woche-Tage) werden mit `0` gefüllt.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Analyse fehlender Werte**\n",
    "- Anzahl der fehlenden Werte (`NaN`) pro Spalte wird berechnet.\n",
    "- Zeilen mit fehlenden Werten werden entfernt.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Speichern der Ergebnisse**\n",
    "- Der kombinierte Datensatz wird in zwei Versionen gespeichert:\n",
    "  - **Mit NaN-Werten**: `final_data_withNaN.csv`.\n",
    "  - **Ohne NaN-Werte**: `final_data.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Vergleich der Zeilenanzahl**\n",
    "- Die Anzahl der Zeilen vor und nach der Bereinigung wird verglichen, um den Verlust durch das Entfernen von `NaN`-Werten zu zeigen.\n",
    "\n",
    "---\n",
    "\n",
    "## **Zweck des Codes**\n",
    "1. **Datenbereinigung**: Sicherstellung von konsistenten und vollständigen Daten.\n",
    "2. **Kombination der Datensätze**: Erstellung einer zentralen, einheitlichen Datenbasis.\n",
    "3. **Markierung besonderer Tage**: Identifikation der Kieler Woche-Tage (`KielerWoche`).\n",
    "4. **Analyse-Ready**: Der bereinigte Datensatz dient als Grundlage für Analysen oder Modelle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Funktion zur Datenexploration\n",
    "def explore_data(df, name):\n",
    "    print(f\"\\n{'='*50}\\nExploration für {name}\\n{'='*50}\")\n",
    "    \n",
    "    # Überblick\n",
    "    print(f\"Form: {df.shape[0]} Zeilen, {df.shape[1]} Spalten\")\n",
    "    print(\"Erste 5 Zeilen:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Spaltennamen und Typen\n",
    "    print(\"\\nSpalten und Datentypen:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    # Fehlende Werte\n",
    "    print(\"\\nFehlende Werte pro Spalte:\")\n",
    "    print(df.isna().sum())\n",
    "    \n",
    "    # Beschreibende Statistik\n",
    "    print(\"\\nBeschreibende Statistik:\")\n",
    "    print(df.describe(include='all'))\n",
    "    \n",
    "    # Duplikate\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    print(f\"\\nAnzahl der Duplikate: {duplicate_count}\")\n",
    "\n",
    "    # Wichtige Spalten\n",
    "    if 'Datum' in df.columns:\n",
    "        print(\"\\nZeitraum der Daten:\")\n",
    "        print(f\"Min Datum: {df['Datum'].min()}, Max Datum: {df['Datum'].max()}\")\n",
    "    else:\n",
    "        print(\"\\nKeine 'Datum'-Spalte in diesem DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import holidays\n",
    "\n",
    "data_pfad= 'kaggel/train.csv'\n",
    "model_data_pfad = 'final_data_train.csv'\n",
    "# Import Data\n",
    "kiwo_data = pd.read_csv('kaggel/kiwo.csv', parse_dates=['Datum'])\n",
    "umsatzdaten_gekuerzt_data = pd.read_csv(data_pfad, parse_dates=['Datum'])\n",
    "wetter_data = pd.read_csv('kaggel/wetter.csv', parse_dates=['Datum'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Exploration für DATA/Kiwo Data\n",
      "==================================================\n",
      "Form: 72 Zeilen, 2 Spalten\n",
      "Erste 5 Zeilen:\n",
      "       Datum  KielerWoche\n",
      "0 2012-06-16            1\n",
      "1 2012-06-17            1\n",
      "2 2012-06-18            1\n",
      "3 2012-06-19            1\n",
      "4 2012-06-20            1\n",
      "\n",
      "Spalten und Datentypen:\n",
      "Datum          datetime64[ns]\n",
      "KielerWoche             int64\n",
      "dtype: object\n",
      "\n",
      "Fehlende Werte pro Spalte:\n",
      "Datum          0\n",
      "KielerWoche    0\n",
      "dtype: int64\n",
      "\n",
      "Beschreibende Statistik:\n",
      "                     Datum  KielerWoche\n",
      "count                   72         72.0\n",
      "mean   2015-12-23 00:00:00          1.0\n",
      "min    2012-06-16 00:00:00          1.0\n",
      "25%    2014-03-24 00:00:00          1.0\n",
      "50%    2015-12-23 00:00:00          1.0\n",
      "75%    2017-09-22 00:00:00          1.0\n",
      "max    2019-06-30 00:00:00          1.0\n",
      "std                    NaN          0.0\n",
      "\n",
      "Anzahl der Duplikate: 0\n",
      "\n",
      "Zeitraum der Daten:\n",
      "Min Datum: 2012-06-16 00:00:00, Max Datum: 2019-06-30 00:00:00\n",
      "\n",
      "==================================================\n",
      "Exploration für DATA/Umsatzdaten Gekürzt\n",
      "==================================================\n",
      "Form: 9334 Zeilen, 4 Spalten\n",
      "Erste 5 Zeilen:\n",
      "        id      Datum  Warengruppe      Umsatz\n",
      "0  1307011 2013-07-01            1  148.828353\n",
      "1  1307021 2013-07-02            1  159.793757\n",
      "2  1307031 2013-07-03            1  111.885594\n",
      "3  1307041 2013-07-04            1  168.864941\n",
      "4  1307051 2013-07-05            1  171.280754\n",
      "\n",
      "Spalten und Datentypen:\n",
      "id                      int64\n",
      "Datum          datetime64[ns]\n",
      "Warengruppe             int64\n",
      "Umsatz                float64\n",
      "dtype: object\n",
      "\n",
      "Fehlende Werte pro Spalte:\n",
      "id             0\n",
      "Datum          0\n",
      "Warengruppe    0\n",
      "Umsatz         0\n",
      "dtype: int64\n",
      "\n",
      "Beschreibende Statistik:\n",
      "                 id                          Datum  Warengruppe       Umsatz\n",
      "count  9.334000e+03                           9334  9334.000000  9334.000000\n",
      "mean   1.559311e+06  2016-01-13 23:56:27.100921344     3.088172   206.749044\n",
      "min    1.307011e+06            2013-07-01 00:00:00     1.000000     7.051201\n",
      "25%    1.410123e+06            2014-10-12 00:00:00     2.000000    96.897441\n",
      "50%    1.601102e+06            2016-01-10 00:00:00     3.000000   161.900831\n",
      "75%    1.704223e+06            2017-04-22 00:00:00     4.000000   280.644663\n",
      "max    1.807315e+06            2018-07-31 00:00:00     6.000000  1879.461831\n",
      "std    1.512503e+05                            NaN     1.489002   144.545189\n",
      "\n",
      "Anzahl der Duplikate: 0\n",
      "\n",
      "Zeitraum der Daten:\n",
      "Min Datum: 2013-07-01 00:00:00, Max Datum: 2018-07-31 00:00:00\n",
      "\n",
      "==================================================\n",
      "Exploration für DATA/Wetter Data\n",
      "==================================================\n",
      "Form: 2601 Zeilen, 5 Spalten\n",
      "Erste 5 Zeilen:\n",
      "       Datum  Bewoelkung  Temperatur  Windgeschwindigkeit  Wettercode\n",
      "0 2012-01-01         8.0      9.8250                   14        58.0\n",
      "1 2012-01-02         7.0      7.4375                   12         NaN\n",
      "2 2012-01-03         8.0      5.5375                   18        63.0\n",
      "3 2012-01-04         4.0      5.6875                   19        80.0\n",
      "4 2012-01-05         6.0      5.3000                   23        80.0\n",
      "\n",
      "Spalten und Datentypen:\n",
      "Datum                  datetime64[ns]\n",
      "Bewoelkung                    float64\n",
      "Temperatur                    float64\n",
      "Windgeschwindigkeit             int64\n",
      "Wettercode                    float64\n",
      "dtype: object\n",
      "\n",
      "Fehlende Werte pro Spalte:\n",
      "Datum                    0\n",
      "Bewoelkung              10\n",
      "Temperatur               0\n",
      "Windgeschwindigkeit      0\n",
      "Wettercode             669\n",
      "dtype: int64\n",
      "\n",
      "Beschreibende Statistik:\n",
      "                               Datum   Bewoelkung   Temperatur  \\\n",
      "count                           2601  2591.000000  2601.000000   \n",
      "mean   2015-12-07 00:08:18.269896192     4.805866    12.099586   \n",
      "min              2012-01-01 00:00:00     0.000000   -10.250000   \n",
      "25%              2014-03-14 00:00:00     3.000000     6.512500   \n",
      "50%              2015-12-24 00:00:00     6.000000    12.000000   \n",
      "75%              2017-10-07 00:00:00     7.000000    17.825000   \n",
      "max              2019-08-01 00:00:00     8.000000    32.671428   \n",
      "std                              NaN     2.578299     7.174357   \n",
      "\n",
      "       Windgeschwindigkeit   Wettercode  \n",
      "count          2601.000000  1932.000000  \n",
      "mean             11.191080    37.484472  \n",
      "min               3.000000     0.000000  \n",
      "25%               8.000000    10.000000  \n",
      "50%              10.000000    28.000000  \n",
      "75%              14.000000    61.000000  \n",
      "max              35.000000    95.000000  \n",
      "std               4.124693    27.567144  \n",
      "\n",
      "Anzahl der Duplikate: 0\n",
      "\n",
      "Zeitraum der Daten:\n",
      "Min Datum: 2012-01-01 00:00:00, Max Datum: 2019-08-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Exploration der einzelnen Dateien\n",
    "explore_data(kiwo_data, \"DATA/Kiwo Data\")\n",
    "explore_data(umsatzdaten_gekuerzt_data, \"DATA/Umsatzdaten Gekürzt\")\n",
    "explore_data(wetter_data, \"DATA/Wetter Data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import holidays\n",
    "\n",
    "# Merge Umsatzdaten mit Wetterdaten auf 'Datum'\n",
    "merged_data = pd.merge(umsatzdaten_gekuerzt_data, wetter_data, on='Datum', how='inner')\n",
    "\n",
    "# Füge KielerWoche-Information hinzu und ersetze fehlende Werte durch 0\n",
    "final_data = pd.merge(merged_data, kiwo_data, on='Datum', how='left')\n",
    "final_data['KielerWoche'] = final_data['KielerWoche'].fillna(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der NaN-Werte pro Spalte:\n",
      "id                        0\n",
      "Datum                     0\n",
      "Warengruppe               0\n",
      "Umsatz                    0\n",
      "Bewoelkung               54\n",
      "Temperatur                0\n",
      "Windgeschwindigkeit       0\n",
      "Wettercode             2309\n",
      "KielerWoche               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Anzahl der NaN-Werte überprüfen\n",
    "nan_counts = final_data.isna().sum()\n",
    "print(\"Anzahl der NaN-Werte pro Spalte:\")\n",
    "print(nan_counts)\n",
    "\n",
    "# Entferne Zeilen mit NaN-Werten\n",
    "clean_data = final_data.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lorda\\AppData\\Local\\Temp\\ipykernel_20564\\1988144829.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_data['Wochentag'] = clean_data['Datum'].dt.dayofweek  # Montag=0, Sonntag=6\n",
      "C:\\Users\\lorda\\AppData\\Local\\Temp\\ipykernel_20564\\1988144829.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_data['Monat'] = clean_data['Datum'].dt.month\n",
      "C:\\Users\\lorda\\AppData\\Local\\Temp\\ipykernel_20564\\1988144829.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_data['Jahr'] = clean_data['Datum'].dt.year\n",
      "C:\\Users\\lorda\\AppData\\Local\\Temp\\ipykernel_20564\\1988144829.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_data['Jahreszeit'] = clean_data['Datum'].dt.month % 12 // 3 + 1  # Frühling=1, Sommer=2, Herbst=3, Winter=4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# **Zeitabhängige Variablen hinzufügen**\n",
    "clean_data['Wochentag'] = clean_data['Datum'].dt.dayofweek  # Montag=0, Sonntag=6\n",
    "clean_data['Monat'] = clean_data['Datum'].dt.month\n",
    "clean_data['Jahr'] = clean_data['Datum'].dt.year\n",
    "\n",
    "clean_data['Jahreszeit'] = clean_data['Datum'].dt.month % 12 // 3 + 1  # Frühling=1, Sommer=2, Herbst=3, Winter=4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lorda\\AppData\\Local\\Temp\\ipykernel_20564\\171020470.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_data['Jahreszeit'] = clean_data['Monat'].apply(get_season)\n",
      "C:\\Users\\lorda\\AppData\\Local\\Temp\\ipykernel_20564\\171020470.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_data['Gefühl'] = clean_data.apply(lambda x: temperature_feeling(x['Temperatur'], x['Jahreszeit']), axis=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Jahreszeit bestimmen\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return \"Winter\"\n",
    "    elif month in [3, 4, 5]:\n",
    "        return \"Frühling\"\n",
    "    elif month in [6, 7, 8]:\n",
    "        return \"Sommer\"\n",
    "    elif month in [9, 10, 11]:\n",
    "        return \"Herbst\"\n",
    "\n",
    "clean_data['Jahreszeit'] = clean_data['Monat'].apply(get_season)\n",
    "\n",
    "# Gefühl abhängig von Temperatur und Jahreszeit\n",
    "def temperature_feeling(temp, season):\n",
    "    if season == \"Winter\":\n",
    "        if temp <= 0:\n",
    "            return \"Kalt\"\n",
    "        elif temp <= 10:\n",
    "            return \"Mild\"\n",
    "        else:\n",
    "            return \"Warm\"\n",
    "    elif season == \"Frühling\":\n",
    "        if temp <= 10:\n",
    "            return \"Kalt\"\n",
    "        elif temp <= 20:\n",
    "            return \"Mild\"\n",
    "        else:\n",
    "            return \"Warm\"\n",
    "    elif season == \"Sommer\":\n",
    "        if temp <= 15:\n",
    "            return \"Kalt\"\n",
    "        elif temp <= 25:\n",
    "            return \"Mild\"\n",
    "        else:\n",
    "            return \"Warm\"\n",
    "    elif season == \"Herbst\":\n",
    "        if temp <= 10:\n",
    "            return \"Kalt\"\n",
    "        elif temp <= 20:\n",
    "            return \"Mild\"\n",
    "        else:\n",
    "            return \"Warm\"\n",
    "\n",
    "clean_data['Gefühl'] = clean_data.apply(lambda x: temperature_feeling(x['Temperatur'], x['Jahreszeit']), axis=1)\n",
    "\n",
    "# Dummy-Encoding\n",
    "gefühl_dummies = pd.get_dummies(clean_data['Gefühl'],prefix='gefühl')\n",
    "\n",
    "# Dummy-Variablen anhängen und Originalspalten löschen\n",
    "clean_data = pd.concat([clean_data,gefühl_dummies], axis=1)\n",
    "#gefühl_dummies.drop(columns=['Gefühl'], inplace=True)\n",
    "\n",
    "clean_data.to_csv('final_data_x.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Feiertage hinzufügen**\n",
    "def get_feiertage(year):\n",
    "    de_holidays = holidays.Germany(years=year)\n",
    "    return list(de_holidays.keys())\n",
    "\n",
    "# Feiertagsinformationen für alle Jahre im Datensatz\n",
    "feiertage_set = {holiday for year in clean_data['Datum'].dt.year.unique() for holiday in get_feiertage(year)}\n",
    "\n",
    "# Feiertagsspalte erstellen\n",
    "clean_data['Feiertag'] = clean_data['Datum'].apply(lambda x: 1 if x.date() in feiertage_set else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# **Besondere Events (KielLauf, Kieler Triathlon) hinzufügen**\n",
    "kieler_triathlon_daten = pd.to_datetime(['2013-08-04', '2014-08-03', '2015-08-02', '2016-08-07', '2017-08-06', \n",
    "                                         '2018-08-05', '2019-08-04'])\n",
    "kiellauf_daten = pd.to_datetime([\"2013-09-08\", \"2014-09-14\", \"2015-09-13\", \"2016-09-11\", \n",
    "                                 \"2017-09-10\", \"2018-09-09\", \"2019-09-08\"])\n",
    "important_games_germany = pd.to_datetime([\n",
    "    # FIFA World Cup 2014\n",
    "    \"2014-07-08\",  # Germany 7–1 Brazil (Semifinal)\n",
    "    \"2014-07-13\",  # Germany 1–0 Argentina (Final)\n",
    "\n",
    "    # UEFA Euro 2016\n",
    "    \"2016-07-02\",  # Germany 1–1 Italy (6–5 on penalties, Quarterfinal)\n",
    "    \"2016-07-07\",  # Germany 0–2 France (Semifinal)\n",
    "\n",
    "    # FIFA Confederations Cup 2017\n",
    "    \"2017-06-19\",  # Germany 3–2 Australia\n",
    "    \"2017-06-22\",  # Germany 1–1 Chile\n",
    "    \"2017-06-25\",  # Germany 3–1 Cameroon\n",
    "    \"2017-06-29\",  # Germany 4–1 Mexico (Semifinal)\n",
    "    \"2017-07-02\",  # Germany 1–0 Chile (Final)\n",
    "\n",
    "    # FIFA World Cup 2018\n",
    "    \"2018-06-17\",  # Germany 0–1 Mexico (Group stage)\n",
    "    \"2018-06-27\",  # Germany 0–2 South Korea (Group stage, eliminated)\n",
    "\n",
    "    # Olympic Games 2016 (Men's Football)\n",
    "    \"2016-08-20\"   # Germany 1–1 Brazil (4–5 on penalties, Final)\n",
    "])\n",
    "\n",
    "clean_data['KielLauf'] = clean_data['Datum'].apply(lambda x: 1 if x.date() in kiellauf_daten.date else 0)\n",
    "clean_data['Kieler_Triathlon'] = clean_data['Datum'].apply(lambda x: 1 if x.date() in kieler_triathlon_daten.date else 0)\n",
    "clean_data['Fußball'] = clean_data['Datum'].apply(lambda x: 1 if x.date() in important_games_germany.date else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# **PaycheckEffect (Gehaltszahlungen)**\n",
    "clean_data['PaycheckEffect'] = clean_data['Datum'].apply(\n",
    "    lambda x: 1 if x.day >= 27 or x.day <= 5 else 0\n",
    ")\n",
    "\n",
    "# Inflation sensitivity mapping based on WarenGruppe\n",
    "sensitivity_mapping = {\n",
    "    1: \"High\",   # Brot\n",
    "    2: \"High\",   # Brötchen\n",
    "    3: \"Moderate\",  # Croissant\n",
    "    4: \"Moderate\",  # Konditorei\n",
    "    5: \"Moderate\",  # Kuchen\n",
    "    6: \"High\"    # Saisonbrot\n",
    "}\n",
    "\n",
    "# Map the sensitivity to the WarenGruppe\n",
    "clean_data[\"InflationSensitivity\"] = clean_data[\"Warengruppe\"].map(sensitivity_mapping)\n",
    "\n",
    "# Perform dummy encoding for sensitivity levels, excluding 'Low'\n",
    "dummy_encoded = pd.get_dummies(clean_data[\"InflationSensitivity\"], prefix=\"Sensitivity\").drop(columns=[\"Sensitivity_Low\"], errors=\"ignore\")\n",
    "\n",
    "# Concatenate the dummy columns with the original DataFrame\n",
    "clean_data = pd.concat([clean_data, dummy_encoded], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# **Windkategorie basierend auf Windgeschwindigkeit**\n",
    "def wind_kategorie(wind):\n",
    "    if wind < 10:\n",
    "        return \"Nicht windig\"\n",
    "    elif wind <= 20:\n",
    "        return \"Windig\"\n",
    "    else:\n",
    "        return \"Sehr windig\" #TODO zu => sehr\n",
    "\n",
    "clean_data['Windkategorie'] = clean_data['Windgeschwindigkeit'].apply(wind_kategorie)\n",
    "\n",
    "# Dummy-Variablen für Windkategorien erstellen\n",
    "wind_dummies = pd.get_dummies(clean_data['Windkategorie'], prefix=\"Wind\")\n",
    "clean_data = pd.concat([clean_data, wind_dummies], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# **Dummy-Encoding für Jahreszeit und Wetterkategorie**\n",
    "jahreszeit_dummies = pd.get_dummies(clean_data['Jahreszeit'], prefix=\"Jahreszeit\")\n",
    "\n",
    "# Dummy-Variablen anhängen und Originalspalten löschen\n",
    "clean_data = pd.concat([clean_data, jahreszeit_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "ferien_kiel = [\n",
    "    # Schulferien 2013\n",
    "    ('2013-01-01', '2013-01-05'),  # Weihnachtsferien\n",
    "    ('2013-03-25', '2013-04-06'),  # Osterferien\n",
    "    ('2013-06-24', '2013-08-03'),  # Sommerferien\n",
    "    ('2013-10-04', '2013-10-19'),  # Herbstferien\n",
    "    ('2013-12-23', '2014-01-04'),  # Weihnachtsferien\n",
    "\n",
    "    # Schulferien 2014\n",
    "    ('2014-04-07', '2014-04-22'),  # Osterferien\n",
    "    ('2014-07-14', '2014-08-23'),  # Sommerferien\n",
    "    ('2014-10-20', '2014-11-01'),  # Herbstferien\n",
    "    ('2014-12-22', '2015-01-06'),  # Weihnachtsferien\n",
    "\n",
    "    # Schulferien 2015\n",
    "    ('2015-04-01', '2015-04-18'),  # Osterferien\n",
    "    ('2015-07-16', '2015-08-29'),  # Sommerferien\n",
    "    ('2015-10-19', '2015-10-31'),  # Herbstferien\n",
    "    ('2015-12-23', '2016-01-06'),  # Weihnachtsferien\n",
    "\n",
    "    # Schulferien 2016\n",
    "    ('2016-03-24', '2016-04-09'),  # Osterferien\n",
    "    ('2016-07-25', '2016-09-03'),  # Sommerferien\n",
    "    ('2016-10-17', '2016-10-29'),  # Herbstferien\n",
    "    ('2016-12-23', '2017-01-07'),  # Weihnachtsferien\n",
    "\n",
    "    # Schulferien 2017\n",
    "    ('2017-04-07', '2017-04-22'),  # Osterferien\n",
    "    ('2017-07-24', '2017-09-02'),  # Sommerferien\n",
    "    ('2017-10-16', '2017-10-28'),  # Herbstferien\n",
    "    ('2017-12-21', '2018-01-06'),  # Weihnachtsferien\n",
    "\n",
    "    # Schulferien 2018\n",
    "    ('2018-03-29', '2018-04-13'),  # Osterferien\n",
    "    ('2018-07-09', '2018-08-18'),  # Sommerferien\n",
    "    ('2018-10-01', '2018-10-13'),  # Herbstferien\n",
    "    ('2018-12-21', '2019-01-04'),  # Weihnachtsferien\n",
    "\n",
    "    # Schulferien 2019\n",
    "    ('2019-04-04', '2019-04-18'),  # Osterferien\n",
    "    ('2019-07-01', '2019-08-10'),  # Sommerferien\n",
    "    ('2019-10-04', '2019-10-19'),  # Herbstferien\n",
    "    ('2019-12-23', '2020-01-06'),  # Weihnachtsferien\n",
    "\n",
    "    # Schulferien 2020\n",
    "    ('2020-03-30', '2020-04-17'),  # Osterferien\n",
    "    ('2020-06-29', '2020-08-08'),  # Sommerferien\n",
    "    ('2020-10-05', '2020-10-17'),  # Herbstferien\n",
    "    ('2020-12-23', '2021-01-06'),  # Weihnachtsferien\n",
    "]\n",
    "\n",
    "# Konvertiere Ferien zu einer Liste von Datumsobjekten\n",
    "ferien_tage = []\n",
    "for start, end in ferien_kiel:\n",
    "    start_date = datetime.strptime(start, '%Y-%m-%d')\n",
    "    end_date = datetime.strptime(end, '%Y-%m-%d')\n",
    "    while start_date <= end_date:\n",
    "        ferien_tage.append(start_date)\n",
    "        start_date += timedelta(days=1)\n",
    "\n",
    "\n",
    "# Set der Ferientage für schnellen Zugriff\n",
    "ferien_set = set(ferien_tage)\n",
    "\n",
    "# Spalte hinzufügen: 1 für Ferien, 0 für keine Ferien\n",
    "clean_data['Ferien'] = clean_data['Datum'].apply(lambda x: 1 if x in ferien_set else 0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Neue Spalte basierend auf Wochentagen erstellen\n",
    "clean_data['Tag_Kategorie'] = clean_data['Wochentag'].apply(lambda x: 'Montag_bis_Freitag' if x < 5 else 'Wochenende')\n",
    "# Neue Spalte für Wochenenden erstellen\n",
    "clean_data['Wochenende'] = clean_data['Wochentag'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Jahr', 'Monat', 'Verbraucherpreisindex', 'Veränderung_Vorjahresmonat',\n",
      "       'Veränderung_Vormonat', 'Inflation_Kategorisierung',\n",
      "       'Inflation_Kategorisierung_Neutral',\n",
      "       'Inflation_Kategorisierung_Positiv',\n",
      "       'Inflation_Kategorisierung_vormonat_Neutral',\n",
      "       'Inflation_Kategorisierung_vormonat_Positiv',\n",
      "       'Inflation_Kategorisierung_vormonat_Neutral.1',\n",
      "       'Inflation_Kategorisierung_vormonat_Positiv.1'],\n",
      "      dtype='object')\n",
      "Index(['Jahr', 'Monat', 'Inflation_Kategorisierung',\n",
      "       'Inflation_Kategorisierung_Neutral',\n",
      "       'Inflation_Kategorisierung_Positiv'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "inflation_data= pd.read_csv('DATA/inflation.csv')\n",
    "print(inflation_data.columns)\n",
    "subset_inflation = inflation_data.drop(columns=[ 'Verbraucherpreisindex', 'Veränderung_Vorjahresmonat',\n",
    "       'Veränderung_Vormonat',\n",
    "       'Inflation_Kategorisierung_vormonat_Neutral',\n",
    "       'Inflation_Kategorisierung_vormonat_Positiv',\n",
    "       'Inflation_Kategorisierung_vormonat_Neutral.1',\n",
    "       'Inflation_Kategorisierung_vormonat_Positiv.1'])\n",
    "print(subset_inflation.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'Datum', 'Warengruppe', 'Umsatz', 'Bewoelkung', 'Temperatur',\n",
      "       'Windgeschwindigkeit', 'Wettercode', 'KielerWoche', 'Wochentag',\n",
      "       'Monat', 'Jahr', 'Jahreszeit', 'Gefühl', 'gefühl_Kalt', 'gefühl_Mild',\n",
      "       'gefühl_Warm', 'Feiertag', 'KielLauf', 'Kieler_Triathlon', 'Fußball',\n",
      "       'PaycheckEffect', 'InflationSensitivity', 'Sensitivity_High',\n",
      "       'Sensitivity_Moderate', 'Windkategorie', 'Wind_Nicht windig',\n",
      "       'Wind_Sehr windig', 'Wind_Windig', 'Jahreszeit_Frühling',\n",
      "       'Jahreszeit_Herbst', 'Jahreszeit_Sommer', 'Jahreszeit_Winter', 'Ferien',\n",
      "       'Tag_Kategorie', 'Wochenende', 'Inflation_Kategorisierung',\n",
      "       'Inflation_Kategorisierung_Neutral',\n",
      "       'Inflation_Kategorisierung_Positiv'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "clean_data = pd.merge(clean_data, subset_inflation, on=['Jahr', 'Monat'], how='left')\n",
    "print(clean_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# **Dummy-Encoding für Jahreszeit und Wetterkategorie**\n",
    "wochentag_dummy = pd.get_dummies(clean_data['Wochentag'], prefix=\"Wochentag\")\n",
    "warrengruppe_dummy = pd.get_dummies(clean_data['Warengruppe'], prefix=\"Warengruppe\")\n",
    "\n",
    "\n",
    "# Dummy-Variablen anhängen und Originalspalten löschen\n",
    "clean_data = pd.concat([clean_data, wochentag_dummy,warrengruppe_dummy], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Spalte umbenennen\n",
    "clean_data.rename(columns={\"Wochentag_0\": \"Montag\"}, inplace=True)\n",
    "clean_data.rename(columns={\"Wochentag_1\": \"Dienstag\"}, inplace=True)\n",
    "clean_data.rename(columns={\"Wochentag_2\": \"Mittwoch\"}, inplace=True)\n",
    "clean_data.rename(columns={\"Wochentag_3\": \"Donnerstag\"}, inplace=True)\n",
    "clean_data.rename(columns={\"Wochentag_4\": \"Freitag\"}, inplace=True)\n",
    "clean_data.rename(columns={\"Wochentag_5\": \"Samstag\"}, inplace=True)\n",
    "clean_data.rename(columns={\"Wochentag_6\": \"Sonntag\"}, inplace=True)\n",
    "\n",
    "\n",
    "# Spalte umbenennen\n",
    "clean_data.rename(columns={\"Warengruppe_1\": \"Brot\"}, inplace=True)\n",
    "clean_data.rename(columns={\"Warengruppe_2\": \"Brötchen\"}, inplace=True)\n",
    "clean_data.rename(columns={\"Warengruppe_3\": \"Croissant\"}, inplace=True)\n",
    "clean_data.rename(columns={\"Warengruppe_4\": \"Konditorei\"}, inplace=True)\n",
    "clean_data.rename(columns={\"Warengruppe_5\": \"Kuchen\"}, inplace=True)\n",
    "clean_data.rename(columns={\"Warengruppe_6\": \"Saisonbrot\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify boolean columns\n",
    "boolean_columns = clean_data.select_dtypes(include=['bool']).columns\n",
    "\n",
    "# Convert boolean columns to numeric\n",
    "clean_data[boolean_columns] = clean_data[boolean_columns].astype(int)\n",
    "\n",
    "\n",
    "clean_data.to_csv(model_data_pfad, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
