{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titel: Import data\n",
    "## Author: Achraf Aboukinana\n",
    "\n",
    "## Beschreibung des Codes\n",
    "\n",
    "Dieser Code dient der Analyse, Bereinigung und Kombination von Datensätzen, um eine zentrale und bereinigte Datenbasis zu erstellen. Die Hauptaufgaben sind wie folgt:\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Datenimport**\n",
    "- Die drei Datensätze `kiwo.csv`, `umsatzdaten_gekuerzt.csv` und `wetterdaten.csv` werden eingelesen.\n",
    "- Die Spalte `Datum` wird als Datumsformat (`datetime`) geparst.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Datenexploration**\n",
    "Eine Funktion `explore_data` analysiert jeden DataFrame:\n",
    "- Form des DataFrames (Zeilen und Spalten).\n",
    "- Vorschau der ersten fünf Zeilen.\n",
    "- Spaltennamen, Datentypen und fehlende Werte pro Spalte.\n",
    "- Beschreibende Statistiken.\n",
    "- Anzahl der Duplikate.\n",
    "- Zeitraum der Daten (falls `Datum`-Spalte vorhanden).\n",
    "\n",
    "Diese Funktion wird auf alle Datensätze angewendet.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Zusammenführung der Datensätze**\n",
    "- **Erster Merge**: `umsatzdaten_gekuerzt_data` und `wetter_data` werden anhand der Spalte `Datum` zusammengeführt.\n",
    "- **Zweiter Merge**: Die zusammengeführten Daten werden mit `kiwo_data` kombiniert, wodurch eine neue Spalte `KielerWoche` entsteht:\n",
    "  - Fehlende Werte in `KielerWoche` (für nicht-Kieler-Woche-Tage) werden mit `0` gefüllt.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Analyse fehlender Werte**\n",
    "- Anzahl der fehlenden Werte (`NaN`) pro Spalte wird berechnet.\n",
    "- Zeilen mit fehlenden Werten werden entfernt.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Speichern der Ergebnisse**\n",
    "- Der kombinierte Datensatz wird in zwei Versionen gespeichert:\n",
    "  - **Mit NaN-Werten**: `final_data_withNaN.csv`.\n",
    "  - **Ohne NaN-Werte**: `final_data.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Vergleich der Zeilenanzahl**\n",
    "- Die Anzahl der Zeilen vor und nach der Bereinigung wird verglichen, um den Verlust durch das Entfernen von `NaN`-Werten zu zeigen.\n",
    "\n",
    "---\n",
    "\n",
    "## **Zweck des Codes**\n",
    "1. **Datenbereinigung**: Sicherstellung von konsistenten und vollständigen Daten.\n",
    "2. **Kombination der Datensätze**: Erstellung einer zentralen, einheitlichen Datenbasis.\n",
    "3. **Markierung besonderer Tage**: Identifikation der Kieler Woche-Tage (`KielerWoche`).\n",
    "4. **Analyse-Ready**: Der bereinigte Datensatz dient als Grundlage für Analysen oder Modelle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import holidays\n",
    "# Import Data\n",
    "kiwo_data = pd.read_csv('kiwo.csv', parse_dates=['Datum'])\n",
    "umsatzdaten_gekuerzt_data = pd.read_csv('umsatzdaten_gekuerzt.csv', parse_dates=['Datum'])\n",
    "wetter_data = pd.read_csv('wetterdaten.csv', parse_dates=['Datum'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Funktion zur Datenexploration\n",
    "def explore_data(df, name):\n",
    "    print(f\"\\n{'='*50}\\nExploration für {name}\\n{'='*50}\")\n",
    "    \n",
    "    # Überblick\n",
    "    print(f\"Form: {df.shape[0]} Zeilen, {df.shape[1]} Spalten\")\n",
    "    print(\"Erste 5 Zeilen:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Spaltennamen und Typen\n",
    "    print(\"\\nSpalten und Datentypen:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    # Fehlende Werte\n",
    "    print(\"\\nFehlende Werte pro Spalte:\")\n",
    "    print(df.isna().sum())\n",
    "    \n",
    "    # Beschreibende Statistik\n",
    "    print(\"\\nBeschreibende Statistik:\")\n",
    "    print(df.describe(include='all'))\n",
    "    \n",
    "    # Duplikate\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    print(f\"\\nAnzahl der Duplikate: {duplicate_count}\")\n",
    "\n",
    "    # Wichtige Spalten\n",
    "    if 'Datum' in df.columns:\n",
    "        print(\"\\nZeitraum der Daten:\")\n",
    "        print(f\"Min Datum: {df['Datum'].min()}, Max Datum: {df['Datum'].max()}\")\n",
    "    else:\n",
    "        print(\"\\nKeine 'Datum'-Spalte in diesem DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Exploration für Kiwo Data\n",
      "==================================================\n",
      "Form: 72 Zeilen, 2 Spalten\n",
      "Erste 5 Zeilen:\n",
      "       Datum  KielerWoche\n",
      "0 2012-06-16            1\n",
      "1 2012-06-17            1\n",
      "2 2012-06-18            1\n",
      "3 2012-06-19            1\n",
      "4 2012-06-20            1\n",
      "\n",
      "Spalten und Datentypen:\n",
      "Datum          datetime64[ns]\n",
      "KielerWoche             int64\n",
      "dtype: object\n",
      "\n",
      "Fehlende Werte pro Spalte:\n",
      "Datum          0\n",
      "KielerWoche    0\n",
      "dtype: int64\n",
      "\n",
      "Beschreibende Statistik:\n",
      "                     Datum  KielerWoche\n",
      "count                   72         72.0\n",
      "mean   2015-12-23 00:00:00          1.0\n",
      "min    2012-06-16 00:00:00          1.0\n",
      "25%    2014-03-24 00:00:00          1.0\n",
      "50%    2015-12-23 00:00:00          1.0\n",
      "75%    2017-09-22 00:00:00          1.0\n",
      "max    2019-06-30 00:00:00          1.0\n",
      "std                    NaN          0.0\n",
      "\n",
      "Anzahl der Duplikate: 0\n",
      "\n",
      "Zeitraum der Daten:\n",
      "Min Datum: 2012-06-16 00:00:00, Max Datum: 2019-06-30 00:00:00\n",
      "\n",
      "==================================================\n",
      "Exploration für Umsatzdaten Gekürzt\n",
      "==================================================\n",
      "Form: 9334 Zeilen, 3 Spalten\n",
      "Erste 5 Zeilen:\n",
      "       Datum  Warengruppe      Umsatz\n",
      "0 2013-07-01            1  148.828353\n",
      "1 2013-07-02            1  159.793757\n",
      "2 2013-07-03            1  111.885594\n",
      "3 2013-07-04            1  168.864941\n",
      "4 2013-07-05            1  171.280754\n",
      "\n",
      "Spalten und Datentypen:\n",
      "Datum          datetime64[ns]\n",
      "Warengruppe             int64\n",
      "Umsatz                float64\n",
      "dtype: object\n",
      "\n",
      "Fehlende Werte pro Spalte:\n",
      "Datum          0\n",
      "Warengruppe    0\n",
      "Umsatz         0\n",
      "dtype: int64\n",
      "\n",
      "Beschreibende Statistik:\n",
      "                               Datum  Warengruppe       Umsatz\n",
      "count                           9334  9334.000000  9334.000000\n",
      "mean   2016-01-13 23:56:27.100921344     3.088172   206.749044\n",
      "min              2013-07-01 00:00:00     1.000000     7.051201\n",
      "25%              2014-10-12 00:00:00     2.000000    96.897441\n",
      "50%              2016-01-10 00:00:00     3.000000   161.900831\n",
      "75%              2017-04-22 00:00:00     4.000000   280.644663\n",
      "max              2018-07-31 00:00:00     6.000000  1879.461831\n",
      "std                              NaN     1.489002   144.545189\n",
      "\n",
      "Anzahl der Duplikate: 0\n",
      "\n",
      "Zeitraum der Daten:\n",
      "Min Datum: 2013-07-01 00:00:00, Max Datum: 2018-07-31 00:00:00\n",
      "\n",
      "==================================================\n",
      "Exploration für Wetter Data\n",
      "==================================================\n",
      "Form: 2601 Zeilen, 5 Spalten\n",
      "Erste 5 Zeilen:\n",
      "       Datum  Bewoelkung  Temperatur  Windgeschwindigkeit  Wettercode\n",
      "0 2012-01-01         8.0      9.8250                   14        58.0\n",
      "1 2012-01-02         7.0      7.4375                   12         NaN\n",
      "2 2012-01-03         8.0      5.5375                   18        63.0\n",
      "3 2012-01-04         4.0      5.6875                   19        80.0\n",
      "4 2012-01-05         6.0      5.3000                   23        80.0\n",
      "\n",
      "Spalten und Datentypen:\n",
      "Datum                  datetime64[ns]\n",
      "Bewoelkung                    float64\n",
      "Temperatur                    float64\n",
      "Windgeschwindigkeit             int64\n",
      "Wettercode                    float64\n",
      "dtype: object\n",
      "\n",
      "Fehlende Werte pro Spalte:\n",
      "Datum                    0\n",
      "Bewoelkung              10\n",
      "Temperatur               0\n",
      "Windgeschwindigkeit      0\n",
      "Wettercode             669\n",
      "dtype: int64\n",
      "\n",
      "Beschreibende Statistik:\n",
      "                               Datum   Bewoelkung   Temperatur  \\\n",
      "count                           2601  2591.000000  2601.000000   \n",
      "mean   2015-12-07 00:08:18.269896192     4.805866    12.099586   \n",
      "min              2012-01-01 00:00:00     0.000000   -10.250000   \n",
      "25%              2014-03-14 00:00:00     3.000000     6.512500   \n",
      "50%              2015-12-24 00:00:00     6.000000    12.000000   \n",
      "75%              2017-10-07 00:00:00     7.000000    17.825000   \n",
      "max              2019-08-01 00:00:00     8.000000    32.671428   \n",
      "std                              NaN     2.578299     7.174357   \n",
      "\n",
      "       Windgeschwindigkeit   Wettercode  \n",
      "count          2601.000000  1932.000000  \n",
      "mean             11.191080    37.484472  \n",
      "min               3.000000     0.000000  \n",
      "25%               8.000000    10.000000  \n",
      "50%              10.000000    28.000000  \n",
      "75%              14.000000    61.000000  \n",
      "max              35.000000    95.000000  \n",
      "std               4.124693    27.567144  \n",
      "\n",
      "Anzahl der Duplikate: 0\n",
      "\n",
      "Zeitraum der Daten:\n",
      "Min Datum: 2012-01-01 00:00:00, Max Datum: 2019-08-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Exploration der einzelnen Dateien\n",
    "explore_data(kiwo_data, \"Kiwo Data\")\n",
    "explore_data(umsatzdaten_gekuerzt_data, \"Umsatzdaten Gekürzt\")\n",
    "explore_data(wetter_data, \"Wetter Data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Jahr  Monat  Verbraucherpreisindex  Veränderung_Vorjahresmonat  \\\n",
      "0  2012      1                   90.6                         2.1   \n",
      "1  2012      2                   91.2                         2.1   \n",
      "2  2012      3                   91.7                         2.1   \n",
      "3  2012      4                   91.6                         2.0   \n",
      "4  2012      5                   91.5                         1.9   \n",
      "\n",
      "   Veränderung_Vormonat Inflation_Kategorisierung  \\\n",
      "0                  -0.1                   Positiv   \n",
      "1                   0.7                   Positiv   \n",
      "2                   0.5                   Positiv   \n",
      "3                  -0.1                   Positiv   \n",
      "4                  -0.1                   Positiv   \n",
      "\n",
      "   Inflation_Kategorisierung_Neutral  Inflation_Kategorisierung_Positiv  \n",
      "0                              False                               True  \n",
      "1                              False                               True  \n",
      "2                              False                               True  \n",
      "3                              False                               True  \n",
      "4                              False                               True  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Datei einlesen mit manuellem Trennzeichen\n",
    "file_path = \"inflation.csv\"  # Pfad zur Datei\n",
    "data = pd.read_csv(file_path, delimiter=',')\n",
    "\n",
    "### nach paar änderungen habe ich den tabelle vorbereiten so dass wir es erstmal mergen und in unsere model benutzen \n",
    "# In eine neue CSV-Datei speichern\n",
    "data.to_csv(\"inflation.csv\", index=False)\n",
    "\n",
    "# Daten anzeigen\n",
    "print(data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der NaN-Werte pro Spalte:\n",
      "Datum                     0\n",
      "Warengruppe               0\n",
      "Umsatz                    0\n",
      "Bewoelkung               54\n",
      "Temperatur                0\n",
      "Windgeschwindigkeit       0\n",
      "Wettercode             2309\n",
      "KielerWoche               0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lorda\\AppData\\Local\\Temp\\ipykernel_21360\\1148871001.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_data['Wochentag'] = clean_data['Datum'].dt.dayofweek  # Montag=0, Sonntag=6\n",
      "C:\\Users\\lorda\\AppData\\Local\\Temp\\ipykernel_21360\\1148871001.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_data['Monat'] = clean_data['Datum'].dt.month\n",
      "C:\\Users\\lorda\\AppData\\Local\\Temp\\ipykernel_21360\\1148871001.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_data['Jahreszeit'] = clean_data['Datum'].dt.month % 12 // 3 + 1  # Frühling=1, Sommer=2, Herbst=3, Winter=4\n",
      "C:\\Users\\lorda\\AppData\\Local\\Temp\\ipykernel_21360\\1148871001.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_data['Wetterkategorie'] = pd.cut(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeilen mit NaN entfernt: 2309\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7009 entries, 0 to 9317\n",
      "Data columns (total 27 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   Datum                 7009 non-null   datetime64[ns]\n",
      " 1   Warengruppe           7009 non-null   int64         \n",
      " 2   Umsatz                7009 non-null   float64       \n",
      " 3   Bewoelkung            7009 non-null   float64       \n",
      " 4   Temperatur            7009 non-null   float64       \n",
      " 5   Wettercode            7009 non-null   float64       \n",
      " 6   KielerWoche           7009 non-null   int32         \n",
      " 7   Wochentag             7009 non-null   int32         \n",
      " 8   Monat                 7009 non-null   int32         \n",
      " 9   Jahreszeit_1          7009 non-null   bool          \n",
      " 10  Jahreszeit_2          7009 non-null   bool          \n",
      " 11  Jahreszeit_3          7009 non-null   bool          \n",
      " 12  Jahreszeit_4          7009 non-null   bool          \n",
      " 13  Wetter_Kalt           7009 non-null   bool          \n",
      " 14  Wetter_Mild           7009 non-null   bool          \n",
      " 15  Wetter_Warm           7009 non-null   bool          \n",
      " 16  Feiertag              7009 non-null   int64         \n",
      " 17  KielLauf              7009 non-null   int64         \n",
      " 18  Kieler_Triathlon      7009 non-null   int64         \n",
      " 19  Fußball               7009 non-null   int64         \n",
      " 20  PaycheckEffect        7009 non-null   int64         \n",
      " 21  InflationSensitivity  7009 non-null   object        \n",
      " 22  Sensitivity_High      7009 non-null   bool          \n",
      " 23  Sensitivity_Moderate  7009 non-null   bool          \n",
      " 24  Wind_Nicht windig     7009 non-null   bool          \n",
      " 25  Wind_Windig           7009 non-null   bool          \n",
      " 26  Wind_Zu windig        7009 non-null   bool          \n",
      "dtypes: bool(12), datetime64[ns](1), float64(4), int32(3), int64(6), object(1)\n",
      "memory usage: 876.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datum</th>\n",
       "      <th>Warengruppe</th>\n",
       "      <th>Umsatz</th>\n",
       "      <th>Bewoelkung</th>\n",
       "      <th>Temperatur</th>\n",
       "      <th>Wettercode</th>\n",
       "      <th>KielerWoche</th>\n",
       "      <th>Wochentag</th>\n",
       "      <th>Monat</th>\n",
       "      <th>Feiertag</th>\n",
       "      <th>KielLauf</th>\n",
       "      <th>Kieler_Triathlon</th>\n",
       "      <th>Fußball</th>\n",
       "      <th>PaycheckEffect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7009</td>\n",
       "      <td>7009.000000</td>\n",
       "      <td>7009.000000</td>\n",
       "      <td>7009.000000</td>\n",
       "      <td>7009.000000</td>\n",
       "      <td>7009.000000</td>\n",
       "      <td>7009.000000</td>\n",
       "      <td>7009.000000</td>\n",
       "      <td>7009.000000</td>\n",
       "      <td>7009.000000</td>\n",
       "      <td>7009.000000</td>\n",
       "      <td>7009.000000</td>\n",
       "      <td>7009.000000</td>\n",
       "      <td>7009.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2016-03-11 22:43:34.352974592</td>\n",
       "      <td>3.100014</td>\n",
       "      <td>200.362704</td>\n",
       "      <td>5.307319</td>\n",
       "      <td>10.726434</td>\n",
       "      <td>36.900128</td>\n",
       "      <td>0.023541</td>\n",
       "      <td>3.020402</td>\n",
       "      <td>6.581110</td>\n",
       "      <td>0.009274</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>0.007847</td>\n",
       "      <td>0.308175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2013-07-01 00:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.051201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.475000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2014-12-18 00:00:00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>94.681895</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2016-03-16 00:00:00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>155.268163</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2017-06-19 00:00:00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>271.400924</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.387500</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2018-07-30 00:00:00</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1879.461831</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.497091</td>\n",
       "      <td>140.506394</td>\n",
       "      <td>2.394701</td>\n",
       "      <td>6.843793</td>\n",
       "      <td>27.095884</td>\n",
       "      <td>0.151625</td>\n",
       "      <td>1.994001</td>\n",
       "      <td>3.670157</td>\n",
       "      <td>0.095860</td>\n",
       "      <td>0.053345</td>\n",
       "      <td>0.046215</td>\n",
       "      <td>0.088242</td>\n",
       "      <td>0.461772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Datum  Warengruppe       Umsatz   Bewoelkung  \\\n",
       "count                           7009  7009.000000  7009.000000  7009.000000   \n",
       "mean   2016-03-11 22:43:34.352974592     3.100014   200.362704     5.307319   \n",
       "min              2013-07-01 00:00:00     1.000000     7.051201     0.000000   \n",
       "25%              2014-12-18 00:00:00     2.000000    94.681895     4.000000   \n",
       "50%              2016-03-16 00:00:00     3.000000   155.268163     6.000000   \n",
       "75%              2017-06-19 00:00:00     4.000000   271.400924     7.000000   \n",
       "max              2018-07-30 00:00:00     6.000000  1879.461831     8.000000   \n",
       "std                              NaN     1.497091   140.506394     2.394701   \n",
       "\n",
       "        Temperatur   Wettercode  KielerWoche    Wochentag        Monat  \\\n",
       "count  7009.000000  7009.000000  7009.000000  7009.000000  7009.000000   \n",
       "mean     10.726434    36.900128     0.023541     3.020402     6.581110   \n",
       "min      -8.475000     0.000000     0.000000     0.000000     1.000000   \n",
       "25%       5.500000    10.000000     0.000000     1.000000     3.000000   \n",
       "50%      10.000000    28.000000     0.000000     3.000000     7.000000   \n",
       "75%      16.387500    61.000000     0.000000     5.000000    10.000000   \n",
       "max      28.875000    95.000000     1.000000     6.000000    12.000000   \n",
       "std       6.843793    27.095884     0.151625     1.994001     3.670157   \n",
       "\n",
       "          Feiertag     KielLauf  Kieler_Triathlon      Fußball  PaycheckEffect  \n",
       "count  7009.000000  7009.000000       7009.000000  7009.000000     7009.000000  \n",
       "mean      0.009274     0.002853          0.002140     0.007847        0.308175  \n",
       "min       0.000000     0.000000          0.000000     0.000000        0.000000  \n",
       "25%       0.000000     0.000000          0.000000     0.000000        0.000000  \n",
       "50%       0.000000     0.000000          0.000000     0.000000        0.000000  \n",
       "75%       0.000000     0.000000          0.000000     0.000000        1.000000  \n",
       "max       1.000000     1.000000          1.000000     1.000000        1.000000  \n",
       "std       0.095860     0.053345          0.046215     0.088242        0.461772  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import holidays\n",
    "\n",
    "# Merge Umsatzdaten mit Wetterdaten auf 'Datum'\n",
    "merged_data = pd.merge(umsatzdaten_gekuerzt_data, wetter_data, on='Datum', how='inner')\n",
    "\n",
    "# Füge KielerWoche-Information hinzu und ersetze fehlende Werte durch 0\n",
    "final_data = pd.merge(merged_data, kiwo_data[['Datum', 'KielerWoche']], on='Datum', how='left')\n",
    "final_data['KielerWoche'] = final_data['KielerWoche'].fillna(0).astype(int)\n",
    "\n",
    "# Anzahl der NaN-Werte überprüfen\n",
    "nan_counts = final_data.isna().sum()\n",
    "print(\"Anzahl der NaN-Werte pro Spalte:\")\n",
    "print(nan_counts)\n",
    "\n",
    "# Entferne Zeilen mit NaN-Werten\n",
    "clean_data = final_data.dropna()\n",
    "\n",
    "# **Zeitabhängige Variablen hinzufügen**\n",
    "clean_data['Wochentag'] = clean_data['Datum'].dt.dayofweek  # Montag=0, Sonntag=6\n",
    "clean_data['Monat'] = clean_data['Datum'].dt.month\n",
    "clean_data['Jahreszeit'] = clean_data['Datum'].dt.month % 12 // 3 + 1  # Frühling=1, Sommer=2, Herbst=3, Winter=4\n",
    "\n",
    "# **Wetterkategorie basierend auf Temperatur**\n",
    "clean_data['Wetterkategorie'] = pd.cut(\n",
    "    clean_data['Temperatur'], \n",
    "    bins=[-10, 5, 15, 30], \n",
    "    labels=['Kalt', 'Mild', 'Warm']\n",
    ")\n",
    "\n",
    "# **Dummy-Encoding für Jahreszeit und Wetterkategorie**\n",
    "jahreszeit_dummies = pd.get_dummies(clean_data['Jahreszeit'], prefix=\"Jahreszeit\")\n",
    "wetter_dummies = pd.get_dummies(clean_data['Wetterkategorie'], prefix=\"Wetter\")\n",
    "\n",
    "# Dummy-Variablen anhängen und Originalspalten löschen\n",
    "clean_data = pd.concat([clean_data, jahreszeit_dummies, wetter_dummies], axis=1)\n",
    "clean_data.drop(columns=['Jahreszeit', 'Wetterkategorie'], inplace=True)\n",
    "\n",
    "# **Feiertage hinzufügen**\n",
    "def get_feiertage(year):\n",
    "    de_holidays = holidays.Germany(years=year)\n",
    "    return list(de_holidays.keys())\n",
    "\n",
    "# Feiertagsinformationen für alle Jahre im Datensatz\n",
    "feiertage_set = {holiday for year in clean_data['Datum'].dt.year.unique() for holiday in get_feiertage(year)}\n",
    "\n",
    "# Feiertagsspalte erstellen\n",
    "clean_data['Feiertag'] = clean_data['Datum'].apply(lambda x: 1 if x.date() in feiertage_set else 0)\n",
    "\n",
    "# **Besondere Events (KielLauf, Kieler Triathlon) hinzufügen**\n",
    "kieler_triathlon_daten = pd.to_datetime(['2013-08-04', '2014-08-03', '2015-08-02', '2016-08-07', '2017-08-06', \n",
    "                                         '2018-08-05', '2019-08-04'])\n",
    "kiellauf_daten = pd.to_datetime([\"2013-09-08\", \"2014-09-14\", \"2015-09-13\", \"2016-09-11\", \n",
    "                                 \"2017-09-10\", \"2018-09-09\", \"2019-09-08\"])\n",
    "important_games_germany = pd.to_datetime([\n",
    "    # FIFA World Cup 2014\n",
    "    \"2014-07-08\",  # Germany 7–1 Brazil (Semifinal)\n",
    "    \"2014-07-13\",  # Germany 1–0 Argentina (Final)\n",
    "\n",
    "    # UEFA Euro 2016\n",
    "    \"2016-07-02\",  # Germany 1–1 Italy (6–5 on penalties, Quarterfinal)\n",
    "    \"2016-07-07\",  # Germany 0–2 France (Semifinal)\n",
    "\n",
    "    # FIFA Confederations Cup 2017\n",
    "    \"2017-06-19\",  # Germany 3–2 Australia\n",
    "    \"2017-06-22\",  # Germany 1–1 Chile\n",
    "    \"2017-06-25\",  # Germany 3–1 Cameroon\n",
    "    \"2017-06-29\",  # Germany 4–1 Mexico (Semifinal)\n",
    "    \"2017-07-02\",  # Germany 1–0 Chile (Final)\n",
    "\n",
    "    # FIFA World Cup 2018\n",
    "    \"2018-06-17\",  # Germany 0–1 Mexico (Group stage)\n",
    "    \"2018-06-27\",  # Germany 0–2 South Korea (Group stage, eliminated)\n",
    "\n",
    "    # Olympic Games 2016 (Men's Football)\n",
    "    \"2016-08-20\"   # Germany 1–1 Brazil (4–5 on penalties, Final)\n",
    "])\n",
    "\n",
    "clean_data['KielLauf'] = clean_data['Datum'].apply(lambda x: 1 if x.date() in kiellauf_daten.date else 0)\n",
    "clean_data['Kieler_Triathlon'] = clean_data['Datum'].apply(lambda x: 1 if x.date() in kieler_triathlon_daten.date else 0)\n",
    "clean_data['Fußball'] = clean_data['Datum'].apply(lambda x: 1 if x.date() in important_games_germany.date else 0)\n",
    "\n",
    "# **PaycheckEffect (Gehaltszahlungen)**\n",
    "clean_data['PaycheckEffect'] = clean_data['Datum'].apply(\n",
    "    lambda x: 1 if x.day >= 27 or x.day <= 5 else 0\n",
    ")\n",
    "\n",
    "# Inflation sensitivity mapping based on WarenGruppe\n",
    "sensitivity_mapping = {\n",
    "    1: \"High\",   # Brot\n",
    "    2: \"High\",   # Brötchen\n",
    "    3: \"Moderate\",  # Croissant\n",
    "    4: \"Moderate\",  # Konditorei\n",
    "    5: \"Moderate\",  # Kuchen\n",
    "    6: \"High\"    # Saisonbrot\n",
    "}\n",
    "\n",
    "# Map the sensitivity to the WarenGruppe\n",
    "clean_data[\"InflationSensitivity\"] = clean_data[\"Warengruppe\"].map(sensitivity_mapping)\n",
    "\n",
    "# Perform dummy encoding for sensitivity levels, excluding 'Low'\n",
    "dummy_encoded = pd.get_dummies(clean_data[\"InflationSensitivity\"], prefix=\"Sensitivity\").drop(columns=[\"Sensitivity_Low\"], errors=\"ignore\")\n",
    "\n",
    "# Concatenate the dummy columns with the original DataFrame\n",
    "clean_data = pd.concat([clean_data, dummy_encoded], axis=1)\n",
    "\n",
    "\n",
    "# **Windkategorie basierend auf Windgeschwindigkeit**\n",
    "def wind_kategorie(wind):\n",
    "    if wind < 10:\n",
    "        return \"Nicht windig\"\n",
    "    elif wind <= 20:\n",
    "        return \"Windig\"\n",
    "    else:\n",
    "        return \"Zu windig\"\n",
    "\n",
    "clean_data['Windkategorie'] = clean_data['Windgeschwindigkeit'].apply(wind_kategorie)\n",
    "\n",
    "# Dummy-Variablen für Windkategorien erstellen\n",
    "wind_dummies = pd.get_dummies(clean_data['Windkategorie'], prefix=\"Wind\")\n",
    "clean_data = pd.concat([clean_data, wind_dummies], axis=1)\n",
    "\n",
    "# Originalspalten löschen\n",
    "clean_data.drop(columns=['Windkategorie', 'Windgeschwindigkeit'], inplace=True)\n",
    "\n",
    "# **Speichern der Ergebnisse**\n",
    "final_data.to_csv('final_data_withNaN.csv', index=False)  # Mit NaN-Werten\n",
    "clean_data.to_csv('final_data.csv', index=False)         # Ohne NaN-Werte\n",
    "\n",
    "# Zeilenanzahl vor und nach dem Entfernen von NaN\n",
    "difference = len(final_data) - len(clean_data)\n",
    "print(f\"Zeilen mit NaN entfernt: {difference}\")\n",
    "\n",
    "# **Zusammenfassung**\n",
    "clean_data.head()\n",
    "clean_data.info()\n",
    "clean_data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainingsdaten: MSE = 14789.79, R² = 0.24\n",
      "Testdaten: MSE = 26200.27, R² = -0.25\n",
      "\n",
      "Koeffizienten der Features:\n",
      "                Feature   Coefficient\n",
      "855    Datum_2016-11-14  1.074071e+11\n",
      "848    Datum_2016-11-07  9.541347e+10\n",
      "1155   Datum_2017-11-27  9.450462e+10\n",
      "330    Datum_2014-11-27  9.351355e+10\n",
      "331    Datum_2014-11-28  9.237311e+10\n",
      "...                 ...           ...\n",
      "251    Datum_2014-08-03 -1.058944e+11\n",
      "1306   Datum_2018-05-10 -1.185600e+11\n",
      "17       Wind_Zu windig -2.871500e+11\n",
      "15    Wind_Nicht windig -2.877656e+11\n",
      "16          Wind_Windig -3.320082e+11\n",
      "\n",
      "[1377 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Bereinigte Daten laden\n",
    "clean_data = pd.read_csv('final_data.csv')\n",
    "\n",
    "# Features und Ziel definieren\n",
    "# Beispiel: Ziel ist \"Umsatz\", Features sind andere numerische Spalten\n",
    "X = clean_data.drop(columns=['Umsatz','KielerWoche','Warengruppe'])  # Features: Alle außer 'Umsatz' und 'Datum'\n",
    "y = clean_data['Umsatz']  # Ziel: Umsatz\n",
    "\n",
    "# Prüfen, ob Kategorien in numerische Werte konvertiert werden müssen\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Train-Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Lineares Regressionsmodell trainieren\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Modellbewertung\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print(f\"Trainingsdaten: MSE = {mse_train:.2f}, R² = {r2_train:.2f}\")\n",
    "print(f\"Testdaten: MSE = {mse_test:.2f}, R² = {r2_test:.2f}\")\n",
    "\n",
    "# Wichtige Koeffizienten und Features\n",
    "coefficients = pd.DataFrame({'Feature': X.columns, 'Coefficient': model.coef_})\n",
    "print(\"\\nKoeffizienten der Features:\")\n",
    "print(coefficients.sort_values(by='Coefficient', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Datum  Warengruppe      Umsatz  Bewoelkung  Temperatur  \\\n",
      "0 2013-07-01            1  148.828353         6.0     17.8375   \n",
      "1 2013-07-02            1  159.793757         3.0     17.3125   \n",
      "2 2013-07-03            1  111.885594         7.0     21.0750   \n",
      "3 2013-07-04            1  168.864941         7.0     18.8500   \n",
      "4 2013-07-05            1  171.280754         5.0     19.9750   \n",
      "\n",
      "   Windgeschwindigkeit  Wettercode  KielerWoche  Temperatur_Bereich_Encoded  \\\n",
      "0                   15        20.0            0                           1   \n",
      "1                   10         NaN            0                           1   \n",
      "2                    6        61.0            0                           2   \n",
      "3                    7        20.0            0                           1   \n",
      "4                   12         NaN            0                           1   \n",
      "\n",
      "   Temperatur_Bereich_Mild  Temperatur_Bereich_Warm  \n",
      "0                     True                    False  \n",
      "1                     True                    False  \n",
      "2                    False                     True  \n",
      "3                     True                    False  \n",
      "4                     True                    False  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 49\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Lineares Regressionsmodell trainieren\u001b[39;00m\n\u001b[0;32m     48\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m---> 49\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Vorhersagen\u001b[39;00m\n\u001b[0;32m     52\u001b[0m y_pred_train \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:609\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    605\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    607\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 609\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    618\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[1;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1061\u001b[0m     )\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Angenommen, du hast bereits das final_data DataFrame\n",
    "\n",
    "# 1. Temperaturbereich festlegen\n",
    "def categorize_temperature(temp):\n",
    "    if temp <= 10:\n",
    "        return 'Kalt'\n",
    "    elif 10 < temp <= 20:\n",
    "        return 'Mild'\n",
    "    else:\n",
    "        return 'Warm'\n",
    "\n",
    "# Erstelle eine neue Spalte 'Temperatur_Bereich' mit den kategorisierten Werten\n",
    "final_data['Temperatur_Bereich'] = final_data['Temperatur'].apply(categorize_temperature)\n",
    "\n",
    "# 2. Kategorisches Encoding mit LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "final_data['Temperatur_Bereich_Encoded'] = label_encoder.fit_transform(final_data['Temperatur_Bereich'])\n",
    "\n",
    "# Alternativ: One-Hot Encoding (wenn du statt numerischer Codes Dummy-Variablen bevorzugst)\n",
    "final_data = pd.get_dummies(final_data, columns=['Temperatur_Bereich'], drop_first=True)\n",
    "\n",
    "# Anzeige der ersten Zeilen des DataFrames\n",
    "print(final_data.head())\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Bereinigte Daten laden\n",
    "clean_data = final_data\n",
    "\n",
    "# Features und Ziel definieren\n",
    "# Beispiel: Ziel ist \"Umsatz\", Features sind andere numerische Spalten\n",
    "X = clean_data.drop(columns=['Umsatz','Datum','KielerWoche','Warengruppe'])  # Features: Alle außer 'Umsatz' und 'Datum'\n",
    "y = clean_data['Umsatz']  # Ziel: Umsatz\n",
    "\n",
    "# Prüfen, ob Kategorien in numerische Werte konvertiert werden müssen\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Train-Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Lineares Regressionsmodell trainieren\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Modellbewertung\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print(f\"Trainingsdaten: MSE = {mse_train:.2f}, R² = {r2_train:.2f}\")\n",
    "print(f\"Testdaten: MSE = {mse_test:.2f}, R² = {r2_test:.2f}\")\n",
    "\n",
    "# Wichtige Koeffizienten und Features\n",
    "coefficients = pd.DataFrame({'Feature': X.columns, 'Coefficient': model.coef_})\n",
    "print(\"\\nKoeffizienten der Features:\")\n",
    "print(coefficients.sort_values(by='Coefficient', ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
